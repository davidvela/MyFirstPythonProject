{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FP\n",
    "\n",
    "## v2 - softmax 2, pandas, \n",
    "## next v3 - GAN , embeddings and visualization:  tensorboard and ...matplot\n",
    "\n",
    "Start writing all my logic in jupyter notebook in order to run them from anaconda! <br>\n",
    "** IMPORTANT ** <br>\n",
    "the network cell should only be intialize once! otherwise the program start creating indexes for the variables!!!! \n",
    "\n",
    "tensorboard --logdir=.\\my_graph\t\n",
    "tensorboard => http://localhost:6006 <br>\n",
    "jupyter => http://localhost:8889\n",
    "\n",
    "## index: \n",
    "<a id='index'/>\n",
    "\n",
    "1. READ DATA \n",
    "    * Class \n",
    "    * files \n",
    "2. [Network](#model)\n",
    "3. [execution](#exec) \n",
    "4. [display](#disp)\n",
    "\n",
    "\n",
    "other: \n",
    "4. [Evaluate](#ev) \n",
    "5. [Test](#ts) \n",
    "6. [Other](#o)\n",
    "\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from types import *\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1511451511.073937"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16:38:31'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=.\\mygraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data manipulation\n"
     ]
    }
   ],
   "source": [
    "def des():  return DESC+'_'+dType #+\"_filt:\"+  filter[0]+str(filter[1])\n",
    "def c2(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 60 ):                  return [1,0]  \n",
    "        elif( df >= 60 ):               return [0,1]      \n",
    "    elif rf==2: \n",
    "        if( df < 60 ):                  return 0\n",
    "        elif( df >= 60 ):               return 1\n",
    "def c4(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 23 ):                  return [1,0,0,0]  #0\n",
    "        elif( df >= 23 and df < 60 ):   return [0,1,0,0]  #1\n",
    "        elif( df >= 60 and df < 93 ):   return [0,0,1,0]  #2\n",
    "        elif( df >= 93 ):               return [0,0,0,1]  #3    \n",
    "    elif rf==2: \n",
    "        if( df < 23 ):                  return 0\n",
    "        elif( df >= 23 and df < 60 ):   return 1\n",
    "        elif( df >= 60 and df < 93 ):   return 2\n",
    "        elif( df >= 93 ):               return 3\n",
    "    # elif rf==3: \n",
    "    #     if  ( df == [1,0,0,0] ):        return 0 \n",
    "    #     elif( df == [0,1,0,0] ):        return 1\n",
    "    #     elif( df == [0,0,1,0] ):        return 2  \n",
    "    #     elif( df == [0,0,0,1] ):        return 3  \n",
    "def cN(df):\n",
    "    global nout\n",
    "    listofzeros = [0] * nout\n",
    "    dfIndex = df #//nRange\n",
    "    # print('{} and {}', (df,dfIndex))\n",
    "    if    0 < dfIndex < nout:   listofzeros[dfIndex] = 1\n",
    "    elif  dfIndex < 0:          listofzeros[0]       = 1\n",
    "    elif  dfIndex >= nout:      listofzeros[nout-1]  = 1\n",
    "    \n",
    "    return listofzeros \n",
    "def cc(x, rv=1):\n",
    "    global nout\n",
    "    if   dType == 'C4':  return c4(x, rv);\n",
    "    elif dType == 'C1':  return cN(x); \n",
    "    elif dType == 'C2':  nout = 2;   return c2(x, rv);\n",
    "def dc(df, val = 1 ):    return df.index(val)  \n",
    "def normalize():     dst[:, 'FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "def mainRead2( path, part, batch_size , all = True, shuffle = True):  \n",
    "    # read by partitions!   \n",
    "    global  spn, dst;\n",
    "    start = time.time()\n",
    "    if all:  dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" )\n",
    "    else:     \n",
    "        columns = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=0, nrows=1)\n",
    "        dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=part*batch_size+1, \n",
    "                           nrows=batch_size, names = columns.columns)\n",
    "    \n",
    "    dst = dst.fillna(0)\n",
    "    if shuffle: dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    dst.insert(2, 'FP_P', dst['FP'] )  \n",
    "    elapsed_time = float(time.time() - start)\n",
    "    print(\"data read - {} - time:{}\" .format(len(dst), elapsed_time ))\n",
    "\n",
    "    # #dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "    # if batch_size > spn: spn = -1\n",
    "    # dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    # dataT  = {'label' : dst.loc[spn:,'FP_P'] , 'data' :  dst.iloc[spn:, 3:] }\n",
    "    # dataE  = {'label' : dst.loc[:spn-1,'FP_P'] , 'data' :  dst.iloc[:spn, 3:] }\n",
    "    #print(\"data read - lenTrain={}-{} & lenEv={}-{} time:{}\" .format(len(dataT[\"data\"]), \n",
    "    #    len(dataT[\"label\"]),len(dataE[\"data\"]),len(dataE[\"label\"]), elapsed_time ))\n",
    "    # dataT= convert_2List(dataT)\n",
    "    # dataE= convert_2List(dataE)\n",
    "    \n",
    "def get_batches(batch_size):\n",
    "    n_batches = int(len( dst.loc[spn:]  ) // batch_size)\n",
    "    print(n_batches*batch_size)\n",
    "    # x,y = dataT[\"data\"][:n_batches*batch_size], dataT[\"label\"][:n_batches*batch_size]\n",
    "    for ii in range(0, len( dst.loc[spn:spn+n_batches*batch_size]) , batch_size ):\n",
    "        #convert to list! \n",
    "        yield dst.iloc[spn+ii: spn+ii+batch_size, 3:].as_matrix().tolist(), dst.loc[spn+ii: spn+ii+batch_size-1, 'FP_P' ].as_matrix().tolist() \n",
    "        \n",
    "def check_perf_CN(predv, dataEv, sk_ev=False ):\n",
    "    gt3 = 0; gtM = 0; \n",
    "    # predvList = predv.tolist()\n",
    "    # assert(len(predv) == len(dataEv['label']))\n",
    "    print(\"denormalization all Evaluation : {} = {}\" .format(len(predv[1]), len(dataEv)))\n",
    "    #for i in range(100):\n",
    "    for i in range(len(dataEv)):\n",
    "        if (i % 1000==0): print(str(i)) #, end=\"__\") \n",
    "        try:\n",
    "            # pred_v = dc( predv.tolist()[i], np.max(predv[i]))\n",
    "            pred_v = predv[1][i][0]\n",
    "            data_v = dataEv[i] if sk_ev  else dc( dataEv[i])\n",
    "            if   dType == 'C4' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C2' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C1':\n",
    "                num = abs(pred_v-data_v)\n",
    "                if num > 3: gt3+=1\n",
    "                if num > 10: gtM+=1\n",
    "        except: print(\"error: i={}, pred={}, data={} -- \".format(i, pred_v, data_v))\n",
    "    print(\"Total: {} GT3: {}  GTM: {}\".format(len(predv[1]), gt3, gtM)) \n",
    "    return gt3, gtM \n",
    "def feed_data(dataJJ, p_abs, d_st = False, p_exp=False, pand=False, p_col = False):\n",
    "    indx=[];   index_col=0 if p_abs else 2 #abs=F => 2 == 6D\n",
    " \n",
    "    # col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = col_df.fillna(0)\n",
    "    print(\"input-no={}\".format( len(col_df )))\n",
    "    \n",
    "    if p_exp:   indx.append(i for i in range(103))\n",
    "    else:       indx = col_df.index\n",
    "    \n",
    "    if p_col: \n",
    "        dataTest_label = []\n",
    "        dataJJ = \"[\"\n",
    "        for i in range(len(col_df)): \n",
    "            dataTest_label.append( cc( int(  col_df.iloc[i][\"fp\"]  )  )) \n",
    "            dataJJ += '{\"m\":\"'+str(i)+'\",'+'\"'+str(col_df.iloc[i].name)+'\"'+\":1},\"\n",
    "        dataJJ += '{\"m\":\"0\"}]';  dataTest_label.append(cc(0))\n",
    "        # dataJJ += ']'\n",
    "        dataJJ = json.loads(dataJJ)\n",
    "\n",
    "    json_df  = pd.DataFrame(columns=indx); df_entry = pd.Series(index=indx)\n",
    "    df_entry = df_entry.fillna(0) \n",
    "   \n",
    "    ccount = Counter()\n",
    "    if(isinstance(dataJJ, list)):json_data = dataJJ\n",
    "    else: json_str=open(dataJJ).read();  json_data = json.loads(json_str)\n",
    "    # for i in range(20):\n",
    "    for i in range(len(json_data)): # print(i)\n",
    "        df_entry *= 0\n",
    "        m = str(json_data[i][\"m\"])\n",
    "        df_entry.name = m\n",
    "        for key in json_data[i]:\n",
    "            if key == \"m\": pass            \n",
    "            else: \n",
    "                key_wz = key if p_abs else (int(key))  #str(int(key)) FRFLO - int // FRALL str!\n",
    "                try: #filling of key - experimental or COMP \n",
    "                    ds_comp = col_df.loc[key_wz]\n",
    "                    if p_exp == True:  #fp key - 0-102   \n",
    "                        co = str(ds_comp['FP'])\n",
    "                        if co == 'nan':  col_key = 102\n",
    "                        else: \n",
    "                            col_key = int(ds_comp['FP'])\n",
    "                            if col_key>101: col_key = 101\n",
    "                            if col_key<0: col_key = 0\n",
    "                    else: col_key = key_wz      \n",
    "                    # df_entry.loc[col_key]\n",
    "                    df_entry[col_key] =  np.float32(json_data[i][key])\n",
    "                except: \n",
    "                    if d_st: print(\"m:{}-c:{} not included\" .format(m, key_wz)); ccount[key_wz] +=1\n",
    "\n",
    "        json_df = json_df.append(df_entry,ignore_index=False)\n",
    "        if i % 1000 == 0: print(\"cycle: {}\".format(i))\n",
    "    print(\"Counter of comp. not included :\"); print(ccount) # print(len(ccount))\n",
    "\n",
    "    if p_col: return json_df.as_matrix().tolist(), dataTest_label\n",
    "    else: \n",
    "        if pand:  return json_df  \n",
    "        else:     return json_df.as_matrix().tolist() \n",
    "#---------------------------------------------------------------------\n",
    "print(\"data manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "#     print(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG        = \"../../_zfp/LOG.txt\"\n",
    "LOGDIR     = \"../../_zfp/data/my_graph/\"\n",
    "LOGDAT     = \"../../_zfp/data/\"\n",
    "\n",
    "spn        = 5000  #5000 -1 = all for training \n",
    "\n",
    "DESC       = \"FRFLO\"\n",
    "# DESC       = \"FRALL1\"\n",
    "dType      = \"C4\" #C1 or C4\n",
    "MMF        = \"MODJJ1\" #2(1) OR 5 (4)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "MODEL_DIR  = LOGDIR + DESC + '/' + DESC + dType +  MMF +\"/\"  \n",
    "model_path = MODEL_DIR + \"model.ckpt\" \n",
    "DSJ        = \"/data_json.txt\"\n",
    "DSC        = \"/datasc.csv\"   \n",
    "DC         = \"/datac.csv\"\n",
    "DL         = \"/datal.csv\"\n",
    "LAB_DS     = LOGDAT + DESC + DL #\"../../_zfp/data/FRFLO/datal.csv\"\n",
    "COL_DS     = LOGDAT + DESC + DC \n",
    "ALL_DSJ    = LOGDAT + DESC + DSJ \n",
    "ALL_DS     = LOGDAT + DESC + DSC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read - 9610 - time:8.465846538543701\n",
      "9610\n"
     ]
    }
   ],
   "source": [
    "mainRead2(ALL_DS, 1, 2, all = True, shuffle = True  ) \n",
    "print(len(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# get the indices of the array where it is not zero\n",
    "dst.iloc[0].nonzero()\n",
    "ds =  dst.iloc[0]\n",
    "print(len(ds.iloc[ds.nonzero()]))\n",
    "ds.iloc[ds.nonzero()]\n",
    "\n",
    "# I will need this for the embedding - but this means I will not be able to use batch - 128; \n",
    "# I will have to process every input individually\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Network  <a id=\"model\"></a> \n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------------------------\n",
    "def get_nns(): \n",
    "    #nns =  str(ninp)+'*'+str(h[0])+'*'+str(h[1])+'*'+str(nout)\n",
    "    nns =  str(ninp)+'*' \n",
    "    for i in range(len(h)):\n",
    "        nns = nns +str(h[i])+'*'\n",
    "    return nns +str(nout)\n",
    "def get_hpar(): return \"lr_%.0E_NN%s\" % (lr, get_nns())\n",
    "\n",
    "def logr(datep = '' , time='', it=1000, nn='', typ='TR', DS='', AC=0, num=0, AC3=0, AC10=0, desc='', startTime='', batch_size=128):\n",
    "    if desc == '': print(\"Log not recorded\"); return \n",
    "    LOG = \"../../_zfp/LOGT2.txt\"\n",
    "    f= open(LOG ,\"a+\") #w,a,\n",
    "    if datep != '':   dats = datep\n",
    "    else:             dats = datetime.now().strftime('%d.%m.%Y') \n",
    "    if time != '':    times = time\n",
    "    else:             times = datetime.now().strftime('%H:%M:%S') \n",
    "\n",
    "    line =  datetime.now().strftime('%d.%m.%Y') + '\\t' + times \n",
    "    line = line + '\\t' + str(it) + '\\t'+  get_nns() +  '\\t' + str(lr)\n",
    "    line = line + '\\t' + typ \n",
    "    line = line + '\\t' + str(DS) + '\\t' + str(AC) + '\\t' + str(num) + '\\t' + str(AC3) + '\\t' +  str(AC10) + '\\t' + desc \n",
    "    line = line + '\\t' + str(batch_size) + '\\t' +  startTime + '\\n' #new\n",
    "\n",
    "    f.write(line);  f.close()\n",
    "    print(\"___Log recorded\")    \n",
    "def restore_model(sess):   \n",
    "    saver= tf.train.Saver() \n",
    "    print(\"Model restored from file: %s\" % model_path)\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "# print(get_hpar())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0, 0, 1, 0]\n",
      "1     [0, 0, 0, 1]\n",
      "2     [0, 0, 1, 0]\n",
      "3     [0, 0, 1, 0]\n",
      "4     [0, 0, 0, 1]\n",
      "5     [0, 0, 0, 1]\n",
      "6     [0, 0, 0, 1]\n",
      "7     [0, 0, 1, 0]\n",
      "8     [0, 0, 1, 0]\n",
      "9     [0, 0, 1, 0]\n",
      "10    [0, 0, 1, 0]\n",
      "Name: FP_P, dtype: object\n",
      "1814*100*40*4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs     = 10\n",
    "disp       = 5\n",
    "batch_s    = 64\n",
    "\n",
    "lr         = 0.01\n",
    "h          = [100 , 40]\n",
    "# h          = [40 , 10]\n",
    "# h = [1000, 500, 250, 125]\n",
    "\n",
    "ninp  = len(dst.columns) - 3 \n",
    "\n",
    "if   dType == 'C4':  nout = 4;   \n",
    "elif dType == 'C1': nout = 102;\n",
    "    \n",
    "#def convert_2List(dst): return {'label' : dst[\"label\"].as_matrix().tolist(), 'data' : dst[\"data\"].as_matrix().tolist()}\n",
    "# dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "dst['FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "\n",
    "print(dst.loc[:10,'FP_P'])\n",
    "print( get_nns() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(inp, nodes, kp, is_train):\n",
    "    # h = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    h = tf.layers.dense( inp, nodes, use_bias=False, activation=None )\n",
    "    h = tf.layers.batch_normalization(h, training=is_train)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.nn.dropout(h, kp)\n",
    "    return h\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "def build_network2(is_train=False):     # Simple NN - with batch normalization (high level)\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    tf.reset_default_graph()\n",
    "    x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "    y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "    inp = x \n",
    "    for i in range(len(h)): \n",
    "        hx = fc(inp,  h[i], kp, is_train)\n",
    "        inp = hx \n",
    "#     h0  = fc(x,  h[0], kp, is_train)\n",
    "#     h1  = fc(h0, h[1], kp, is_train)\n",
    "    out = tf.layers.dense( hx, nout, use_bias=False, activation=None )\n",
    "    #out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    #out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # softmaxT = tf.nn.softmax(out)\n",
    "        softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "\n",
    "        prediction=tf.reduce_max(y,1)\n",
    "        correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    with tf.name_scope(\"xent\"): #loss!\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y))\n",
    "        tf.summary.scalar(\"xent\", cost)\n",
    "    with tf.name_scope(\"train\"): #opt!\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "    summ = tf.summary.merge_all()   \n",
    "    \n",
    "    return out, accuracy, softmaxT, x, y, optimizer, summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network built\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction, accuracy, softmaxT, x, y, optimizer, summ  = build_network2()\n",
    "print(\"network built\")\n",
    "\n",
    "\n",
    "saver= tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def build_network3(is_train=False):     # RNN - embeddings\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    \n",
    "    # I cannot use embeddings because they only allow int32 and int64\n",
    "    # but my data is in percentage - decimals ... - experiment \n",
    "    # embedding = tf.Variable(tf.random_uniform((ninp, h[0]), -1, 1))\n",
    "    # h0 = tf.nn.embedding_lookup(embedding, x)\n",
    "    # h0 = tf.gather(embedding, x)\n",
    "\n",
    "    #only solution: \n",
    "    # - Train: \n",
    "    #index = dst[i].nonzero()\n",
    "    #for j in index:\n",
    "    #    wtemp.append(w0[j]) \n",
    "    #    xtmp.append(dst[i].iloc[j])\n",
    "    #wtemp.dot(xtmp)  \n",
    "    #run optimize feed_dict h0: h0, y: y ... \n",
    "    \n",
    "    # h0 = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    # h0 = tf.layers.dense( x, h[0], use_bias=False, activation=None )\n",
    "    # h0 = tf.layers.batch_normalization(h0, training=is_train)\n",
    "    # h0 = tf.nn.relu(h0)\n",
    "    # h0 = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    h1 = tf.layers.dense( h0, h[1], use_bias=False, activation=None )\n",
    "    h1 = tf.layers.batch_normalization(h1, training=is_train)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    # h1 = tf.nn.dropout(h1, kp)\n",
    "    \n",
    "    out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "    out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    " \n",
    "    # softmaxT = tf.nn.softmax(out)\n",
    "    softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "            \n",
    "    prediction=tf.reduce_max(y,1)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return out, accuracy, softmaxT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN built\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "        return out   \n",
    "    \n",
    "extra_class = 0        \n",
    "def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(x, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        class_logits  = tf.layers.dense( h1, nout+extra_class, use_bias=False, activation=None )\n",
    "        # out = tf.layers.batch_normalization(out, training=is_train)\n",
    "        # out = tf.nn.relu(out)\n",
    "        # out = tf.nn.dropout(out, kp)\n",
    "\n",
    "        if extra_class:\n",
    "            real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "            fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "        else:\n",
    "            real_class_logits = class_logits\n",
    "            fake_class_logits = 0.\n",
    "            \n",
    "        mx = tf.reduce_max(real_class_logits, 1, keep_dims=True)\n",
    "        stable_real_class_logits = real_class_logits - mx\n",
    "        gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_real_class_logits), 1)) + tf.squeeze(mx) - fake_class_logits\n",
    "        out = tf.nn.softmax(class_logits)\n",
    "        return out, class_logits, gan_logits, features\n",
    "        \n",
    "def model_loss(input_real, input_z, output_dim, y, num_classes, label_mask, alpha=0.2, drop_rate=0.):\n",
    "    g_size_mult = 32\n",
    "    d_size_mult = 64\n",
    "    \n",
    "    g_model = generator(input_z, output_dim, alpha=alpha, size_mult=g_size_mult)\n",
    "    d_on_data = discriminator(input_real, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_real, class_logits_on_data, gan_logits_on_data, data_features = d_on_data\n",
    "    d_on_samples = discriminator(g_model, reuse=True, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = d_on_samples\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return d_loss, g_loss, correct, masked_correct, g_model\n",
    "\n",
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    for t in t_vars:\n",
    "        assert t in d_vars or t in g_vars\n",
    "    d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "    shrink_lr = tf.assign(learning_rate, learning_rate * 0.9)\n",
    "    return d_train_opt, g_train_opt, shrink_lr\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.learning_rate = tf.Variable(learning_rate, trainable=False)\n",
    "        self.input_real, self.input_z, self.y, self.label_mask = model_inputs(real_size, z_size)\n",
    "        self.drop_rate = tf.placeholder_with_default(.5, (), \"drop_rate\")\n",
    "        \n",
    "        loss_results = model_loss(self.input_real, self.input_z,\n",
    "                                    real_size[2], self.y, num_classes, label_mask=self.label_mask, alpha=0.2,\n",
    "                                    drop_rate=self.drop_rate) \n",
    "        \n",
    "        self.d_loss, self.g_loss, self.correct, self.masked_correct, self.samples = loss_results       \n",
    "        \n",
    "        self.d_opt, self.g_opt, self.shrink_lr = model_opt(self.d_loss, self.g_loss, self.learning_rate, beta1)\n",
    "        \n",
    "\n",
    "# real_size = (32,32,3)\n",
    "# z_size = 100\n",
    "# learning_rate = 0.0003\n",
    "\n",
    "# # net = GAN(real_size, z_size, learning_rate)\n",
    "\n",
    "# x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "# z = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"z\")\n",
    "# y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "# lm= tf.placeholder(tf.int32, (None), name='label_mask')\n",
    "print(\"GAN built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network1 - TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def train(it = 100, disp=50, batch_size = 128):    \n",
    "    print(\"____TRAINING...\") #dst.loc[spn:,'FP_P'] dst.iloc[spn:, 3:]  \n",
    "    display_step =  disp \n",
    "\n",
    "    dataTest = {'label' : [] , 'data' :  [] };\n",
    "    #dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    \n",
    "    #dataT['data'].append(dataTest['data']) ;     md.dataT['label'].append(dataTest['label']) \n",
    "    print(\"data read - lenTrain={}-{} \" .format(len(dataTest[\"data\"]), len(dataTest[\"label\"]) ))\n",
    "\n",
    "    total_batch  = int(len(dst.loc[spn:]) / batch_size)\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # restore_model(sess)  #Run if I want to retrain an existing model\n",
    "        writer = tf.summary.FileWriter(MODEL_DIR+\"tboard/\", sess.graph )\n",
    "        \n",
    "        start = time.time()\n",
    "        for i in range(it):            \n",
    "            for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "                # xtb, ytb = dc.next_batch(batch_size, dataT['data'], dataT['label'])\n",
    "                sess.run(optimizer, feed_dict={x: xtb, y: ytb})\n",
    "                if ii % display_step ==0: #record_step == 0:\n",
    "                    [train_accuracy] = sess.run([accuracy], feed_dict={x: xtb, y: ytb }) \n",
    "                    #s = sess.run(summ, feed_dict={x: xtb, y: ytb })\n",
    "                    #[train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: xtb, y: ytb }) \n",
    "                    #writer.add_summary(s, i)\n",
    "                    \n",
    "                    elapsed_time = float(time.time() - start)\n",
    "                    reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "                    rp_s = str(reviews_per_second)[0:5]\n",
    "                    tr_ac = str(train_accuracy)[:5]  \n",
    "                    print('Epoch: {} batch: {} / {} - %Speed(it/disp_step): {} - tr_ac {}' .format(i, ii, total_batch, rp_s, tr_ac ))\n",
    "                    \n",
    "            #sess.run(optimizer, feed_dict={x: dataTest['data'], y: dataTest['label']})\n",
    "            #[train_accuracy] = sess.run([accuracy], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "            #print(\"ColC-{}\".format(train_accuracy))\n",
    "            \n",
    "            #ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5]            \n",
    "            test_accuracy = sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  })\n",
    "            ev_ac = str(test_accuracy)[:5]            \n",
    "            print(\"E Ac:\", ev_ac)\n",
    "\n",
    "            #tr_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()   }) )[:5]  \n",
    "            train_accuracy = sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()   })\n",
    "            tr_ac = str( train_accuracy )[:5] \n",
    "            print(\"T Ac:\", tr_ac)\n",
    "        \n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        \n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    logr( it=it, typ='TR', DS=DESC, AC=tr_ac,num=len(dst)-spn, AC3=0, AC10=0, desc=des(), startTime=startTime, batch_size=batch_size )\n",
    "    logr( it=it, typ='EV', DS=DESC, AC=ev_ac,num=spn , AC3=0, AC10=0, desc=des() )\n",
    "#---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(dst.iloc[:spn-1,2:3]))\n",
    "# test = dst.loc[:2, 'FP_P']\n",
    "# print(type(test.tolist()))\n",
    "# test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate( ): \n",
    "    print(\"_____EVALUATION...\")\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        tr_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()    }) )[:5]  \n",
    "        ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5] \n",
    "        print(\"Training   Accuracy:\", tr_ac )\n",
    "        print(\"Evaluation Accuracy:\", ev_ac )\n",
    "        predv, softv = sess.run([prediction, softmaxT], feed_dict={x: dst.iloc[:spn, 3:]  }) # , y: md.dataE['label'] \n",
    "        # maxa = sess.run([prediction], feed_dict={y: predv })\n",
    "    print(\"Preview the first predictions:\")\n",
    "    for i in range(20):\n",
    "        print(\"RealVal: {}  - PP value: {}\".format( dc( dst.loc[:spn-1,'FP_P'][i])   , \n",
    "                                                    dc( predv.tolist()[i], np.max(predv[i]))  ))\n",
    "    gt3, gtM = check_perf_CN(softv, dst.loc[:spn-1,'FP_P'], False)\n",
    "    logr(  it=0, typ='EV', AC=ev_ac,DS=DESC, num=spn, AC3=gt3, AC10=gtM, desc=des(), startTime=startTime, batch_size=batch_s )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tests(url_test = 'url', p_col=False):  \n",
    "    print(\"_____TESTS...\")    \n",
    "    global DESC\n",
    "    # Load test data \n",
    "    dataTest = {'label' : [] , 'data' :  [] }; pred_val = []\n",
    "    if p_col: dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    else: \n",
    "        if url_test != 'url':  \n",
    "            json_data = url_test + \"data_json6.txt\"\n",
    "            tmpLab = pd.read_csv(url_test + \"datal6.csv\", sep=',', usecols=[0,1])    \n",
    "            tmpLab = tmpLab.loc[:,'fp']\n",
    "            abstcc = False\n",
    "        else: \n",
    "            json_str, tmpLab = get_data_test(\"FRALL\")\n",
    "            json_data = json.loads(json_str)\n",
    "            abstcc = True\n",
    "            DESC =  'matnrList...'\n",
    "        \n",
    "        dataTest['data']  = feed_data(json_data, p_abs=abstcc , d_st=True)\n",
    "        \n",
    "        dataTest['label'] = []\n",
    "        [dataTest['label'].append( cc(x) ) for x in tmpLab ]\n",
    "    # Predict data \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        # predv = sess.run( prediction, feed_dict={x: dataTest['data']}) \n",
    "        ts_acn = '0'\n",
    "        ts_acn, predv, sf = sess.run( [accuracy, prediction, softmaxT], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "        ts_ac = str(ts_acn) \n",
    "        print(\"test ac = {}\".format(ts_ac))\n",
    "    # print(dataTest['label']);     print(sf)\n",
    "    range_ts = len(predv) if len(predv)<20 else 20\n",
    "    for i in range( range_ts ):\n",
    "        # print(\"RealVal: {}  - PP value: {}\".format( dc( dataTest['label'][i]), dc( predv.tolist()[i], np.max(predv[i]))  ))  \n",
    "        print(\"{} RealVal: {} - {} - PP: {} PR: {}\".format( i, dc( dataTest['label'][i]), sf[1][i][0],  sf[1][i], sf[0][i]   ))\n",
    "\n",
    "    # return\n",
    "    gt3, gtM = check_perf_CN(sf, dataTest[\"label\"], False)\n",
    "    logr( it=0, typ='TS', DS=DESC, AC=ts_acn ,num=len(dataTest[\"label\"]),  AC3=gt3, AC10=gtM, desc=des(), batch_size=batch_s )  \n",
    "\n",
    "    outfile = '../../_zfp/data/export2' \n",
    "    np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "    np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTIONS <a id=\"exec\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 18\n",
    "# print(\"  PP: {} PR: {} \". format(   sf[1][i], sf[0][i]    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____TRAINING...\n",
      "data read - lenTrain=0-0 \n",
      "4608\n",
      "Epoch: 0 batch: 0 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.625\n",
      "Epoch: 0 batch: 5 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.406\n",
      "Epoch: 0 batch: 10 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.546\n",
      "Epoch: 0 batch: 15 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.656\n",
      "Epoch: 0 batch: 20 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.609\n",
      "Epoch: 0 batch: 25 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.609\n",
      "Epoch: 0 batch: 30 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.625\n",
      "Epoch: 0 batch: 35 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.671\n",
      "Epoch: 0 batch: 40 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.578\n",
      "Epoch: 0 batch: 45 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.609\n",
      "Epoch: 0 batch: 50 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.687\n",
      "Epoch: 0 batch: 55 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.656\n",
      "Epoch: 0 batch: 60 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.734\n",
      "Epoch: 0 batch: 65 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.546\n",
      "Epoch: 0 batch: 70 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.578\n",
      "E Ac: 0.633\n",
      "T Ac: 0.642\n",
      "4608\n",
      "Epoch: 1 batch: 0 / 72 - %Speed(it/disp_step): 0.149 - tr_ac 0.640\n",
      "Epoch: 1 batch: 5 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.593\n",
      "Epoch: 1 batch: 10 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.625\n",
      "Epoch: 1 batch: 15 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.671\n",
      "Epoch: 1 batch: 20 / 72 - %Speed(it/disp_step): 0.126 - tr_ac 0.640\n",
      "Epoch: 1 batch: 25 / 72 - %Speed(it/disp_step): 0.121 - tr_ac 0.687\n",
      "Epoch: 1 batch: 30 / 72 - %Speed(it/disp_step): 0.117 - tr_ac 0.718\n",
      "Epoch: 1 batch: 35 / 72 - %Speed(it/disp_step): 0.112 - tr_ac 0.671\n",
      "Epoch: 1 batch: 40 / 72 - %Speed(it/disp_step): 0.109 - tr_ac 0.765\n",
      "Epoch: 1 batch: 45 / 72 - %Speed(it/disp_step): 0.105 - tr_ac 0.734\n",
      "Epoch: 1 batch: 50 / 72 - %Speed(it/disp_step): 0.102 - tr_ac 0.734\n",
      "Epoch: 1 batch: 55 / 72 - %Speed(it/disp_step): 0.099 - tr_ac 0.609\n",
      "Epoch: 1 batch: 60 / 72 - %Speed(it/disp_step): 0.096 - tr_ac 0.703\n",
      "Epoch: 1 batch: 65 / 72 - %Speed(it/disp_step): 0.093 - tr_ac 0.703\n",
      "Epoch: 1 batch: 70 / 72 - %Speed(it/disp_step): 0.090 - tr_ac 0.609\n",
      "E Ac: 0.653\n",
      "T Ac: 0.660\n",
      "4608\n",
      "Epoch: 2 batch: 0 / 72 - %Speed(it/disp_step): 0.152 - tr_ac 0.640\n",
      "Epoch: 2 batch: 5 / 72 - %Speed(it/disp_step): 0.149 - tr_ac 0.703\n",
      "Epoch: 2 batch: 10 / 72 - %Speed(it/disp_step): 0.145 - tr_ac 0.625\n",
      "Epoch: 2 batch: 15 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.656\n",
      "Epoch: 2 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.718\n",
      "Epoch: 2 batch: 25 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.765\n",
      "Epoch: 2 batch: 30 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.734\n",
      "Epoch: 2 batch: 35 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.734\n",
      "Epoch: 2 batch: 40 / 72 - %Speed(it/disp_step): 0.128 - tr_ac 0.75\n",
      "Epoch: 2 batch: 45 / 72 - %Speed(it/disp_step): 0.126 - tr_ac 0.718\n",
      "Epoch: 2 batch: 50 / 72 - %Speed(it/disp_step): 0.123 - tr_ac 0.828\n",
      "Epoch: 2 batch: 55 / 72 - %Speed(it/disp_step): 0.121 - tr_ac 0.718\n",
      "Epoch: 2 batch: 60 / 72 - %Speed(it/disp_step): 0.119 - tr_ac 0.75\n",
      "Epoch: 2 batch: 65 / 72 - %Speed(it/disp_step): 0.116 - tr_ac 0.687\n",
      "Epoch: 2 batch: 70 / 72 - %Speed(it/disp_step): 0.114 - tr_ac 0.640\n",
      "E Ac: 0.721\n",
      "T Ac: 0.737\n",
      "4608\n",
      "Epoch: 3 batch: 0 / 72 - %Speed(it/disp_step): 0.152 - tr_ac 0.671\n",
      "Epoch: 3 batch: 5 / 72 - %Speed(it/disp_step): 0.149 - tr_ac 0.75\n",
      "Epoch: 3 batch: 10 / 72 - %Speed(it/disp_step): 0.147 - tr_ac 0.781\n",
      "Epoch: 3 batch: 15 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.765\n",
      "Epoch: 3 batch: 20 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.718\n",
      "Epoch: 3 batch: 25 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.75\n",
      "Epoch: 3 batch: 30 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.75\n",
      "Epoch: 3 batch: 35 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.781\n",
      "Epoch: 3 batch: 40 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.734\n",
      "Epoch: 3 batch: 45 / 72 - %Speed(it/disp_step): 0.128 - tr_ac 0.781\n",
      "Epoch: 3 batch: 50 / 72 - %Speed(it/disp_step): 0.126 - tr_ac 0.718\n",
      "Epoch: 3 batch: 55 / 72 - %Speed(it/disp_step): 0.124 - tr_ac 0.796\n",
      "Epoch: 3 batch: 60 / 72 - %Speed(it/disp_step): 0.123 - tr_ac 0.734\n",
      "Epoch: 3 batch: 65 / 72 - %Speed(it/disp_step): 0.121 - tr_ac 0.703\n",
      "Epoch: 3 batch: 70 / 72 - %Speed(it/disp_step): 0.119 - tr_ac 0.546\n",
      "E Ac: 0.706\n",
      "T Ac: 0.724\n",
      "4608\n",
      "Epoch: 4 batch: 0 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.656\n",
      "Epoch: 4 batch: 5 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.859\n",
      "Epoch: 4 batch: 10 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.828\n",
      "Epoch: 4 batch: 15 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.734\n",
      "Epoch: 4 batch: 20 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.75\n",
      "Epoch: 4 batch: 25 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.703\n",
      "Epoch: 4 batch: 30 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.718\n",
      "Epoch: 4 batch: 35 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.828\n",
      "Epoch: 4 batch: 40 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.796\n",
      "Epoch: 4 batch: 45 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.781\n",
      "Epoch: 4 batch: 50 / 72 - %Speed(it/disp_step): 0.128 - tr_ac 0.781\n",
      "Epoch: 4 batch: 55 / 72 - %Speed(it/disp_step): 0.126 - tr_ac 0.781\n",
      "Epoch: 4 batch: 60 / 72 - %Speed(it/disp_step): 0.125 - tr_ac 0.859\n",
      "Epoch: 4 batch: 65 / 72 - %Speed(it/disp_step): 0.124 - tr_ac 0.671\n",
      "Epoch: 4 batch: 70 / 72 - %Speed(it/disp_step): 0.122 - tr_ac 0.734\n",
      "E Ac: 0.759\n",
      "T Ac: 0.794\n",
      "4608\n",
      "Epoch: 5 batch: 0 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.875\n",
      "Epoch: 5 batch: 5 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.828\n",
      "Epoch: 5 batch: 10 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.828\n",
      "Epoch: 5 batch: 15 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.859\n",
      "Epoch: 5 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.796\n",
      "Epoch: 5 batch: 25 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.828\n",
      "Epoch: 5 batch: 30 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.812\n",
      "Epoch: 5 batch: 35 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.734\n",
      "Epoch: 5 batch: 40 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.843\n",
      "Epoch: 5 batch: 45 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.828\n",
      "Epoch: 5 batch: 50 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.812\n",
      "Epoch: 5 batch: 55 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.765\n",
      "Epoch: 5 batch: 60 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.843\n",
      "Epoch: 5 batch: 65 / 72 - %Speed(it/disp_step): 0.128 - tr_ac 0.781\n",
      "Epoch: 5 batch: 70 / 72 - %Speed(it/disp_step): 0.127 - tr_ac 0.703\n",
      "E Ac: 0.753\n",
      "T Ac: 0.801\n",
      "4608\n",
      "Epoch: 6 batch: 0 / 72 - %Speed(it/disp_step): 0.145 - tr_ac 0.843\n",
      "Epoch: 6 batch: 5 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.828\n",
      "Epoch: 6 batch: 10 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.796\n",
      "Epoch: 6 batch: 15 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.765\n",
      "Epoch: 6 batch: 20 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.875\n",
      "Epoch: 6 batch: 25 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.828\n",
      "Epoch: 6 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.765\n",
      "Epoch: 6 batch: 35 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.734\n",
      "Epoch: 6 batch: 40 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.843\n",
      "Epoch: 6 batch: 45 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.765\n",
      "Epoch: 6 batch: 50 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.828\n",
      "Epoch: 6 batch: 55 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.843\n",
      "Epoch: 6 batch: 60 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.812\n",
      "Epoch: 6 batch: 65 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.828\n",
      "Epoch: 6 batch: 70 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.765\n",
      "E Ac: 0.760\n",
      "T Ac: 0.800\n",
      "4608\n",
      "Epoch: 7 batch: 0 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.812\n",
      "Epoch: 7 batch: 5 / 72 - %Speed(it/disp_step): 0.143 - tr_ac 0.890\n",
      "Epoch: 7 batch: 10 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.859\n",
      "Epoch: 7 batch: 15 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.796\n",
      "Epoch: 7 batch: 20 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.859\n",
      "Epoch: 7 batch: 25 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.781\n",
      "Epoch: 7 batch: 30 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.875\n",
      "Epoch: 7 batch: 35 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.796\n",
      "Epoch: 7 batch: 40 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.875\n",
      "Epoch: 7 batch: 45 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.796\n",
      "Epoch: 7 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.843\n",
      "Epoch: 7 batch: 55 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.828\n",
      "Epoch: 7 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 batch: 65 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.765\n",
      "Epoch: 7 batch: 70 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.734\n",
      "E Ac: 0.796\n",
      "T Ac: 0.842\n",
      "4608\n",
      "Epoch: 8 batch: 0 / 72 - %Speed(it/disp_step): 0.144 - tr_ac 0.812\n",
      "Epoch: 8 batch: 5 / 72 - %Speed(it/disp_step): 0.143 - tr_ac 0.875\n",
      "Epoch: 8 batch: 10 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.812\n",
      "Epoch: 8 batch: 15 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.843\n",
      "Epoch: 8 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.843\n",
      "Epoch: 8 batch: 25 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.843\n",
      "Epoch: 8 batch: 30 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.75\n",
      "Epoch: 8 batch: 35 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.843\n",
      "Epoch: 8 batch: 40 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.906\n",
      "Epoch: 8 batch: 45 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.859\n",
      "Epoch: 8 batch: 50 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.828\n",
      "Epoch: 8 batch: 55 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.812\n",
      "Epoch: 8 batch: 60 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.781\n",
      "Epoch: 8 batch: 65 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.812\n",
      "Epoch: 8 batch: 70 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.781\n",
      "E Ac: 0.805\n",
      "T Ac: 0.855\n",
      "4608\n",
      "Epoch: 9 batch: 0 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.828\n",
      "Epoch: 9 batch: 5 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.906\n",
      "Epoch: 9 batch: 10 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.828\n",
      "Epoch: 9 batch: 15 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.812\n",
      "Epoch: 9 batch: 20 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.781\n",
      "Epoch: 9 batch: 25 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.828\n",
      "Epoch: 9 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.859\n",
      "Epoch: 9 batch: 35 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.828\n",
      "Epoch: 9 batch: 40 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.906\n",
      "Epoch: 9 batch: 45 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.875\n",
      "Epoch: 9 batch: 50 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.828\n",
      "Epoch: 9 batch: 55 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.859\n",
      "Epoch: 9 batch: 60 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.843\n",
      "Epoch: 9 batch: 65 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.718\n",
      "Epoch: 9 batch: 70 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.781\n",
      "E Ac: 0.806\n",
      "T Ac: 0.853\n",
      "4608\n",
      "Epoch: 10 batch: 0 / 72 - %Speed(it/disp_step): 0.142 - tr_ac 0.812\n",
      "Epoch: 10 batch: 5 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.875\n",
      "Epoch: 10 batch: 10 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.875\n",
      "Epoch: 10 batch: 15 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.890\n",
      "Epoch: 10 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.812\n",
      "Epoch: 10 batch: 25 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.812\n",
      "Epoch: 10 batch: 30 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.906\n",
      "Epoch: 10 batch: 35 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.859\n",
      "Epoch: 10 batch: 40 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.906\n",
      "Epoch: 10 batch: 45 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.875\n",
      "Epoch: 10 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.812\n",
      "Epoch: 10 batch: 55 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.828\n",
      "Epoch: 10 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.859\n",
      "Epoch: 10 batch: 65 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.75\n",
      "Epoch: 10 batch: 70 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.75\n",
      "E Ac: 0.806\n",
      "T Ac: 0.861\n",
      "4608\n",
      "Epoch: 11 batch: 0 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.812\n",
      "Epoch: 11 batch: 5 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.828\n",
      "Epoch: 11 batch: 10 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.875\n",
      "Epoch: 11 batch: 15 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.875\n",
      "Epoch: 11 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.921\n",
      "Epoch: 11 batch: 25 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.875\n",
      "Epoch: 11 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.843\n",
      "Epoch: 11 batch: 35 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.875\n",
      "Epoch: 11 batch: 40 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.937\n",
      "Epoch: 11 batch: 45 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.875\n",
      "Epoch: 11 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.890\n",
      "Epoch: 11 batch: 55 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.828\n",
      "Epoch: 11 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.921\n",
      "Epoch: 11 batch: 65 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.843\n",
      "Epoch: 11 batch: 70 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.75\n",
      "E Ac: 0.812\n",
      "T Ac: 0.872\n",
      "4608\n",
      "Epoch: 12 batch: 0 / 72 - %Speed(it/disp_step): 0.141 - tr_ac 0.843\n",
      "Epoch: 12 batch: 5 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.921\n",
      "Epoch: 12 batch: 10 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.843\n",
      "Epoch: 12 batch: 15 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.890\n",
      "Epoch: 12 batch: 20 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.859\n",
      "Epoch: 12 batch: 25 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.906\n",
      "Epoch: 12 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.843\n",
      "Epoch: 12 batch: 35 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.843\n",
      "Epoch: 12 batch: 40 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.859\n",
      "Epoch: 12 batch: 45 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.812\n",
      "Epoch: 12 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.890\n",
      "Epoch: 12 batch: 55 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.843\n",
      "Epoch: 12 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.890\n",
      "Epoch: 12 batch: 65 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.812\n",
      "Epoch: 12 batch: 70 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.734\n",
      "E Ac: 0.810\n",
      "T Ac: 0.872\n",
      "4608\n",
      "Epoch: 13 batch: 0 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.890\n",
      "Epoch: 13 batch: 5 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.875\n",
      "Epoch: 13 batch: 10 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.859\n",
      "Epoch: 13 batch: 15 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.843\n",
      "Epoch: 13 batch: 20 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.859\n",
      "Epoch: 13 batch: 25 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.890\n",
      "Epoch: 13 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.843\n",
      "Epoch: 13 batch: 35 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.812\n",
      "Epoch: 13 batch: 40 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.890\n",
      "Epoch: 13 batch: 45 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.859\n",
      "Epoch: 13 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.906\n",
      "Epoch: 13 batch: 55 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.875\n",
      "Epoch: 13 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.890\n",
      "Epoch: 13 batch: 65 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.843\n",
      "Epoch: 13 batch: 70 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.843\n",
      "E Ac: 0.816\n",
      "T Ac: 0.882\n",
      "4608\n",
      "Epoch: 14 batch: 0 / 72 - %Speed(it/disp_step): 0.140 - tr_ac 0.921\n",
      "Epoch: 14 batch: 5 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.859\n",
      "Epoch: 14 batch: 10 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.875\n",
      "Epoch: 14 batch: 15 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.859\n",
      "Epoch: 14 batch: 20 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.875\n",
      "Epoch: 14 batch: 25 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.859\n",
      "Epoch: 14 batch: 30 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.937\n",
      "Epoch: 14 batch: 35 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.859\n",
      "Epoch: 14 batch: 40 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.890\n",
      "Epoch: 14 batch: 45 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.859\n",
      "Epoch: 14 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.906\n",
      "Epoch: 14 batch: 55 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.859\n",
      "Epoch: 14 batch: 60 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.906\n",
      "Epoch: 14 batch: 65 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.843\n",
      "Epoch: 14 batch: 70 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.796\n",
      "E Ac: 0.811\n",
      "T Ac: 0.883\n",
      "4608\n",
      "Epoch: 15 batch: 0 / 72 - %Speed(it/disp_step): 0.139 - tr_ac 0.812\n",
      "Epoch: 15 batch: 5 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.875\n",
      "Epoch: 15 batch: 10 / 72 - %Speed(it/disp_step): 0.138 - tr_ac 0.937\n",
      "Epoch: 15 batch: 15 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.906\n",
      "Epoch: 15 batch: 20 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.906\n",
      "Epoch: 15 batch: 25 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.921\n",
      "Epoch: 15 batch: 30 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.906\n",
      "Epoch: 15 batch: 35 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.875\n",
      "Epoch: 15 batch: 40 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.968\n",
      "Epoch: 15 batch: 45 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 batch: 50 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.921\n",
      "Epoch: 15 batch: 55 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.843\n",
      "Epoch: 15 batch: 60 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.875\n",
      "Epoch: 15 batch: 65 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.875\n",
      "Epoch: 15 batch: 70 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.828\n",
      "E Ac: 0.820\n",
      "T Ac: 0.896\n",
      "4608\n",
      "Epoch: 16 batch: 0 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.890\n",
      "Epoch: 16 batch: 5 / 72 - %Speed(it/disp_step): 0.137 - tr_ac 0.875\n",
      "Epoch: 16 batch: 10 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.906\n",
      "Epoch: 16 batch: 15 / 72 - %Speed(it/disp_step): 0.136 - tr_ac 0.875\n",
      "Epoch: 16 batch: 20 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.937\n",
      "Epoch: 16 batch: 25 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.890\n",
      "Epoch: 16 batch: 30 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.906\n",
      "Epoch: 16 batch: 35 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.875\n",
      "Epoch: 16 batch: 40 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.921\n",
      "Epoch: 16 batch: 45 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.921\n",
      "Epoch: 16 batch: 50 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.937\n",
      "Epoch: 16 batch: 55 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.875\n",
      "Epoch: 16 batch: 60 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.921\n",
      "Epoch: 16 batch: 65 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.828\n",
      "Epoch: 16 batch: 70 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.875\n",
      "E Ac: 0.828\n",
      "T Ac: 0.899\n",
      "4608\n",
      "Epoch: 17 batch: 0 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.953\n",
      "Epoch: 17 batch: 5 / 72 - %Speed(it/disp_step): 0.135 - tr_ac 0.875\n",
      "Epoch: 17 batch: 10 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.859\n",
      "Epoch: 17 batch: 15 / 72 - %Speed(it/disp_step): 0.134 - tr_ac 0.906\n",
      "Epoch: 17 batch: 20 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.921\n",
      "Epoch: 17 batch: 25 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.875\n",
      "Epoch: 17 batch: 30 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.859\n",
      "Epoch: 17 batch: 35 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.937\n",
      "Epoch: 17 batch: 40 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.890\n",
      "Epoch: 17 batch: 45 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.859\n",
      "Epoch: 17 batch: 50 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.906\n",
      "Epoch: 17 batch: 55 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.906\n",
      "Epoch: 17 batch: 60 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.890\n",
      "Epoch: 17 batch: 65 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.875\n",
      "Epoch: 17 batch: 70 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.875\n",
      "E Ac: 0.820\n",
      "T Ac: 0.896\n",
      "4608\n",
      "Epoch: 18 batch: 0 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.890\n",
      "Epoch: 18 batch: 5 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.906\n",
      "Epoch: 18 batch: 10 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.812\n",
      "Epoch: 18 batch: 15 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.890\n",
      "Epoch: 18 batch: 20 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.906\n",
      "Epoch: 18 batch: 25 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.906\n",
      "Epoch: 18 batch: 30 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.890\n",
      "Epoch: 18 batch: 35 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.906\n",
      "Epoch: 18 batch: 40 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.953\n",
      "Epoch: 18 batch: 45 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.890\n",
      "Epoch: 18 batch: 50 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.921\n",
      "Epoch: 18 batch: 55 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.906\n",
      "Epoch: 18 batch: 60 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.875\n",
      "Epoch: 18 batch: 65 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.921\n",
      "Epoch: 18 batch: 70 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.812\n",
      "E Ac: 0.812\n",
      "T Ac: 0.886\n",
      "4608\n",
      "Epoch: 19 batch: 0 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.859\n",
      "Epoch: 19 batch: 5 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.890\n",
      "Epoch: 19 batch: 10 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.875\n",
      "Epoch: 19 batch: 15 / 72 - %Speed(it/disp_step): 0.133 - tr_ac 0.906\n",
      "Epoch: 19 batch: 20 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.937\n",
      "Epoch: 19 batch: 25 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.937\n",
      "Epoch: 19 batch: 30 / 72 - %Speed(it/disp_step): 0.132 - tr_ac 0.890\n",
      "Epoch: 19 batch: 35 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.890\n",
      "Epoch: 19 batch: 40 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.953\n",
      "Epoch: 19 batch: 45 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.843\n",
      "Epoch: 19 batch: 50 / 72 - %Speed(it/disp_step): 0.131 - tr_ac 0.906\n",
      "Epoch: 19 batch: 55 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.937\n",
      "Epoch: 19 batch: 60 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.906\n",
      "Epoch: 19 batch: 65 / 72 - %Speed(it/disp_step): 0.130 - tr_ac 0.875\n",
      "Epoch: 19 batch: 70 / 72 - %Speed(it/disp_step): 0.129 - tr_ac 0.843\n",
      "E Ac: 0.825\n",
      "T Ac: 0.907\n",
      "Model saved in file: ../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/model.ckpt\n",
      "Optimization Finished!\n",
      "___Log recorded\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "epochs     = 20\n",
    "train_accuracies, test_accuracies = [], []\n",
    "train(epochs, disp, batch_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____EVALUATION...\n",
      "Model restored from file: ../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/model.ckpt\n",
      "Training   Accuracy: 0.902\n",
      "Evaluation Accuracy: 0.829\n",
      "Preview the first predictions:\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "denormalization all Evaluation : 5000 = 5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "Total: 5000 GT3: 869  GTM: 869\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "evaluate( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____TESTS...\n",
      "input-no=1814\n",
      "cycle: 0\n",
      "m:308210-c:657716 not included\n",
      "m:607654-c:659609 not included\n",
      "m:632416-c:600229 not included\n",
      "m:632416-c:105671 not included\n",
      "m:632416-c:600256 not included\n",
      "m:632416-c:192114 not included\n",
      "m:632416-c:131357 not included\n",
      "m:632416-c:131306 not included\n",
      "m:632416-c:181023 not included\n",
      "m:632416-c:107159 not included\n",
      "m:632416-c:100182 not included\n",
      "m:632416-c:192002 not included\n",
      "m:632416-c:104814 not included\n",
      "m:632416-c:600180 not included\n",
      "m:632416-c:131341 not included\n",
      "m:632416-c:600236 not included\n",
      "m:632416-c:600338 not included\n",
      "m:632416-c:131305 not included\n",
      "m:632416-c:131026 not included\n",
      "m:632416-c:131303 not included\n",
      "m:632416-c:106148 not included\n",
      "m:632416-c:104774 not included\n",
      "m:632416-c:107353 not included\n",
      "m:632416-c:600237 not included\n",
      "m:632416-c:107714 not included\n",
      "m:632416-c:600247 not included\n",
      "m:632416-c:104557 not included\n",
      "m:632416-c:614552 not included\n",
      "m:632416-c:600227 not included\n",
      "m:632416-c:614235 not included\n",
      "m:632416-c:600224 not included\n",
      "m:632416-c:600252 not included\n",
      "m:632632-c:906195 not included\n",
      "m:632632-c:900081 not included\n",
      "m:632632-c:643368 not included\n",
      "m:632632-c:905210 not included\n",
      "m:632632-c:178713 not included\n",
      "m:632632-c:906246 not included\n",
      "m:632632-c:104241 not included\n",
      "m:632632-c:904987 not included\n",
      "m:632632-c:906228 not included\n",
      "m:632632-c:906234 not included\n",
      "m:633650-c:178429 not included\n",
      "m:633652-c:178429 not included\n",
      "m:634190-c:172585 not included\n",
      "m:634190-c:160065 not included\n",
      "m:634190-c:656991 not included\n",
      "m:634190-c:116216 not included\n",
      "m:634190-c:164136 not included\n",
      "m:634190-c:613113 not included\n",
      "m:634190-c:657531 not included\n",
      "m:634330-c:600283 not included\n",
      "m:634330-c:131168 not included\n",
      "m:634330-c:903936 not included\n",
      "m:634832-c:613373 not included\n",
      "m:634832-c:100985 not included\n",
      "m:634832-c:100954 not included\n",
      "m:635055-c:192517 not included\n",
      "m:635056-c:192517 not included\n",
      "m:635056-c:173437 not included\n",
      "m:635059-c:192517 not included\n",
      "m:635059-c:192161 not included\n",
      "m:635059-c:107854 not included\n",
      "m:635059-c:173437 not included\n",
      "m:635955-c:178429 not included\n",
      "m:637117-c:100013 not included\n",
      "m:640737-c:903656 not included\n",
      "m:640744-c:131460 not included\n",
      "m:640745-c:131460 not included\n",
      "m:641547-c:106148 not included\n",
      "m:641547-c:131357 not included\n",
      "m:641547-c:107353 not included\n",
      "m:641547-c:181204 not included\n",
      "m:641547-c:659973 not included\n",
      "m:641547-c:600324 not included\n",
      "m:641547-c:657858 not included\n",
      "m:641547-c:657707 not included\n",
      "m:641547-c:192002 not included\n",
      "m:641547-c:115614 not included\n",
      "m:641547-c:614235 not included\n",
      "m:641547-c:106929 not included\n",
      "m:641547-c:602537 not included\n",
      "m:641547-c:657856 not included\n",
      "m:642045-c:903656 not included\n",
      "m:642045-c:131460 not included\n",
      "m:642077-c:903656 not included\n",
      "m:642078-c:903656 not included\n",
      "m:642410-c:105370 not included\n",
      "m:642584-c:900175 not included\n",
      "m:642584-c:100103 not included\n",
      "m:642904-c:904694 not included\n",
      "m:648652-c:621180 not included\n",
      "m:648652-c:128714 not included\n",
      "m:648652-c:660472 not included\n",
      "m:648652-c:660450 not included\n",
      "m:648652-c:106234 not included\n",
      "m:648652-c:657014 not included\n",
      "m:648652-c:173462 not included\n",
      "m:648652-c:613621 not included\n",
      "m:648652-c:656153 not included\n",
      "m:648652-c:172904 not included\n",
      "m:648652-c:115121 not included\n",
      "m:648652-c:111545 not included\n",
      "m:648652-c:106233 not included\n",
      "m:648652-c:621270 not included\n",
      "m:648652-c:128713 not included\n",
      "m:649248-c:172381 not included\n",
      "m:649248-c:621329 not included\n",
      "m:654512-c:107544 not included\n",
      "m:654512-c:657280 not included\n",
      "m:654512-c:173483 not included\n",
      "m:654512-c:188069 not included\n",
      "m:657282-c:619724 not included\n",
      "m:657282-c:660551 not included\n",
      "m:668545-c:600324 not included\n",
      "m:668545-c:906371 not included\n",
      "m:668545-c:996058 not included\n",
      "m:668545-c:192002 not included\n",
      "m:668545-c:906342 not included\n",
      "m:668545-c:106228 not included\n",
      "m:668545-c:906339 not included\n",
      "m:668545-c:106229 not included\n",
      "m:669362-c:762238 not included\n",
      "m:671711-c:100984 not included\n",
      "m:671711-c:100954 not included\n",
      "m:672522-c:100509 not included\n",
      "m:728171-c:903016 not included\n",
      "m:942926-c:131186 not included\n",
      "m:942926-c:110098 not included\n",
      "m:942926-c:182161 not included\n",
      "m:942926-c:131137 not included\n",
      "m:942926-c:690957 not included\n",
      "m:942926-c:114089 not included\n",
      "m:942926-c:130180 not included\n",
      "m:942926-c:131217 not included\n",
      "m:942926-c:164401 not included\n",
      "m:942926-c:131359 not included\n",
      "m:942926-c:100264 not included\n",
      "m:942926-c:131320 not included\n",
      "Counter of comp. not included :\n",
      "Counter({903656: 4, 192002: 3, 192517: 3, 131460: 3, 178429: 3, 600324: 2, 131357: 2, 107353: 2, 100954: 2, 614235: 2, 173437: 2, 106148: 2, 903936: 1, 906246: 1, 100103: 1, 131341: 1, 600237: 1, 621329: 1, 600338: 1, 107544: 1, 656153: 1, 904987: 1, 181023: 1, 115121: 1, 643368: 1, 172585: 1, 906234: 1, 657707: 1, 659973: 1, 104241: 1, 657716: 1, 160065: 1, 104774: 1, 660551: 1, 107854: 1, 900175: 1, 100182: 1, 172381: 1, 656991: 1, 131168: 1, 130180: 1, 906339: 1, 131186: 1, 906342: 1, 131217: 1, 172904: 1, 104557: 1, 104814: 1, 903016: 1, 192114: 1, 600180: 1, 657014: 1, 100984: 1, 100985: 1, 657531: 1, 621180: 1, 762238: 1, 657280: 1, 600256: 1, 906371: 1, 131137: 1, 107714: 1, 182161: 1, 110098: 1, 106228: 1, 173462: 1, 107159: 1, 614552: 1, 659609: 1, 105370: 1, 100509: 1, 115614: 1, 600224: 1, 192161: 1, 600227: 1, 600229: 1, 900081: 1, 100264: 1, 602537: 1, 173483: 1, 600236: 1, 100013: 1, 106929: 1, 600247: 1, 111545: 1, 131359: 1, 600252: 1, 106229: 1, 657856: 1, 657858: 1, 178713: 1, 105671: 1, 128713: 1, 128714: 1, 619724: 1, 116216: 1, 131026: 1, 906195: 1, 181204: 1, 164401: 1, 621270: 1, 106233: 1, 996058: 1, 600283: 1, 131320: 1, 905210: 1, 188069: 1, 660450: 1, 690957: 1, 131303: 1, 131305: 1, 131306: 1, 164136: 1, 906228: 1, 613621: 1, 904694: 1, 114089: 1, 660472: 1, 613113: 1, 106234: 1, 613373: 1})\n",
      "Model restored from file: ../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/FRFLO/FRFLOC4MODJJ1/model.ckpt\n",
      "test ac = 0.85061\n",
      "0 RealVal: 1 - 2 - PP: [2 3 1 0] PR: [  9.99763668e-01   2.20962524e-04   1.53893234e-05   1.85961802e-11]\n",
      "1 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [ 0.65334862  0.33630836  0.00959727  0.00074583]\n",
      "2 RealVal: 2 - 3 - PP: [3 2 1 0] PR: [  9.65726018e-01   3.42733003e-02   7.51318737e-07   6.21333193e-11]\n",
      "3 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  5.02554357e-01   4.91947144e-01   5.40702231e-03   9.15022611e-05]\n",
      "4 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  9.99999881e-01   1.44041778e-07   8.83455600e-11   7.35112341e-24]\n",
      "5 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  8.98516536e-01   1.01411112e-01   7.23002086e-05   2.57279158e-08]\n",
      "6 RealVal: 3 - 2 - PP: [2 3 1 0] PR: [  1.00000000e+00   1.16587682e-14   1.10007193e-14   2.54316557e-32]\n",
      "7 RealVal: 2 - 3 - PP: [3 2 1 0] PR: [  8.87879193e-01   1.11818403e-01   3.01765627e-04   6.83661540e-07]\n",
      "8 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.20603395e-01   7.93720409e-02   2.45557076e-05   1.21485033e-09]\n",
      "9 RealVal: 2 - 1 - PP: [1 2 3 0] PR: [ 0.31914845  0.29993975  0.21181369  0.16909812]\n",
      "10 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.94198322e-01   5.80173172e-03   1.67197350e-11   2.03632077e-18]\n",
      "11 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [ 0.70600563  0.28002915  0.01259706  0.00136811]\n",
      "12 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  8.00796986e-01   1.77082255e-01   2.17987876e-02   3.21989181e-04]\n",
      "13 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  8.13371420e-01   1.83795884e-01   2.80266232e-03   3.00126540e-05]\n",
      "14 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   4.31899343e-11   8.48140481e-12   1.66509869e-29]\n",
      "15 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.99311447e-01   6.88575616e-04   1.20478150e-11   7.95047054e-25]\n",
      "16 RealVal: 3 - 2 - PP: [2 3 1 0] PR: [  9.78474736e-01   1.94021352e-02   2.12269719e-03   4.59089705e-07]\n",
      "17 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   9.06204711e-09   1.15703847e-09   1.59702681e-22]\n",
      "18 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  8.38595986e-01   1.60442755e-01   9.61024547e-04   2.62032984e-07]\n",
      "19 RealVal: 3 - 2 - PP: [2 3 1 0] PR: [ 0.49162614  0.44907358  0.0518671   0.0074332 ]\n",
      "denormalization all Evaluation : 984 = 984\n",
      "0\n",
      "Total: 984 GT3: 147  GTM: 147\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "url_test = \"../../_zfp/data/FREXP1/\" ; DESC     = \"FREXP1_6\"\n",
    "tests(url_test, p_col=False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSFDUNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2061c7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_accuracies, label='Train', alpha=0.5)\n",
    "plt.plot(test_accuracies, label='Test', alpha=0.5)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding by FAM\n",
    "get data / get FAM <br>\n",
    "if am > 0 => 1; lookup tab.  => visualization embeddings in script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logic... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# outfile = '../../_zfp/data/export.xlsx' \n",
    "\n",
    "# workbook   = xlsxwriter.Workbook(outfile)\n",
    "# worksheet1 = workbook.add_worksheet()\n",
    "# worksheet1.write('A1', 'M')\n",
    "# worksheet1.write(0, 0, 'Hello')  \n",
    "# for i in range(len(sf[0])):\n",
    "#     worksheet1.write(0, i , sf[0][i])  \n",
    "#     worksheet1.write(1, i , sf[1][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# outfile = '../../_zfp/data/export.csv' \n",
    "# f2= open(outfile,\"a+\")\n",
    "# output_writer = csv.writer(f2, delimiter=\"\\t\")\n",
    "# output_writer.writerows(sf)\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = '../../_zfp/data/export2' \n",
    "# np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "# np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display visualizations <a id=\"disp\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = outfile = '../../_zfp/data/FRFLO/datasc.csv' \n",
    "# dst  =  pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\")\n",
    "Y  = dst.loc[:,'FP'].as_matrix().tolist()\n",
    "X  = dst.loc[:, 'M'].as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1423b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 2 - Create plot. \n",
    "a = 1\n",
    "if a == 0: \n",
    "    plt.hist(Y)\n",
    "else: \n",
    "    plt.xlabel('M')\n",
    "    plt.ylabel('FP')\n",
    "    plt.grid(True)\n",
    "    N = 2 #50\n",
    "    colors = np.random.rand(N)\n",
    "    area = 1 #np.pi * (15 * np.random.rand(N))**2  # 0 to 15 point radii\n",
    "\n",
    "    #plt.plot(X, Y, color='blue', marker='o', label='FP Comp')\n",
    "    #plt.plot(X, Y, 'bo', label='FP Comp')\n",
    "    plt.scatter(X,Y, s=6, c='b', marker='o', cmap=None, norm=None, vmin=60, vmax=101, alpha=None,  label='FP Comp')\n",
    "    # plt.plot(X, Y,  s=area, c=colors, alpha=0.5) #'bo', label='FP Comp',\n",
    "    plt.legend()\n",
    "\n",
    "# 3 - Display plot. \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
