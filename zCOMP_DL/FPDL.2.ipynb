{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP\n",
    "\n",
    "## v2 - softmax 2, pandas, \n",
    "## next v3 - GAN , embeddings and visualization:  tensorboard and ...matplot\n",
    "\n",
    "Start writing all my logic in jupyter notebook in order to run them from anaconda! <br>\n",
    "** IMPORTANT ** <br>\n",
    "the network cell should only be intialize once! otherwise the program start creating indexes for the variables!!!! \n",
    "\n",
    "tensorboard --logdir=.\\my_graph\t\n",
    "tensorboard => http://localhost:6006 <br>\n",
    "jupyter => http://localhost:8889\n",
    "\n",
    "## index: \n",
    "<a id='index'/>\n",
    "\n",
    "1. READ DATA \n",
    "    * Class \n",
    "    * files \n",
    "2. [Network](#model)\n",
    "3. [execution](#exec) \n",
    "4. [display](#disp)\n",
    "\n",
    "\n",
    "other: \n",
    "4. [Evaluate](#ev) \n",
    "5. [Test](#ts) \n",
    "6. [Other](#o)\n",
    "\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from types import *\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1511533785.84954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15:29:45'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=.\\mygraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data manipulation\n"
     ]
    }
   ],
   "source": [
    "def des():  return DESC+'_'+dType #+\"_filt:\"+  filter[0]+str(filter[1])\n",
    "def c2(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 60 ):                  return [1,0]  \n",
    "        elif( df >= 60 ):               return [0,1]      \n",
    "    elif rf==2: \n",
    "        if( df < 60 ):                  return 0\n",
    "        elif( df >= 60 ):               return 1\n",
    "def c4(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 23 ):                  return [1,0,0,0]  #0\n",
    "        elif( df >= 23 and df < 60 ):   return [0,1,0,0]  #1\n",
    "        elif( df >= 60 and df < 93 ):   return [0,0,1,0]  #2\n",
    "        elif( df >= 93 ):               return [0,0,0,1]  #3    \n",
    "    elif rf==2: \n",
    "        if( df < 23 ):                  return 0\n",
    "        elif( df >= 23 and df < 60 ):   return 1\n",
    "        elif( df >= 60 and df < 93 ):   return 2\n",
    "        elif( df >= 93 ):               return 3\n",
    "    # elif rf==3: \n",
    "    #     if  ( df == [1,0,0,0] ):        return 0 \n",
    "    #     elif( df == [0,1,0,0] ):        return 1\n",
    "    #     elif( df == [0,0,1,0] ):        return 2  \n",
    "    #     elif( df == [0,0,0,1] ):        return 3  \n",
    "def cN(df):\n",
    "    global nout\n",
    "    listofzeros = [0] * nout\n",
    "    dfIndex = df #//nRange\n",
    "    # print('{} and {}', (df,dfIndex))\n",
    "    if    0 < dfIndex < nout:   listofzeros[dfIndex] = 1\n",
    "    elif  dfIndex < 0:          listofzeros[0]       = 1\n",
    "    elif  dfIndex >= nout:      listofzeros[nout-1]  = 1\n",
    "    \n",
    "    return listofzeros \n",
    "def cc(x, rv=1):\n",
    "    global nout\n",
    "    if   dType == 'C4':  return c4(x, rv);\n",
    "    elif dType == 'C1':  return cN(x); \n",
    "    elif dType == 'C2':  nout = 2;   return c2(x, rv);\n",
    "def dc(df, val = 1 ):    return df.index(val)  \n",
    "def normalize():     dst[:, 'FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "def mainRead2( path, part, batch_size , all = True, shuffle = True):  \n",
    "    # read by partitions!   \n",
    "    global  spn, dst;\n",
    "    start = time.time()\n",
    "    if all:  dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" )\n",
    "    else:     \n",
    "        columns = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=0, nrows=1)\n",
    "        dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=part*batch_size+1, \n",
    "                           nrows=batch_size, names = columns.columns)\n",
    "    \n",
    "    dst = dst.fillna(0)\n",
    "    if shuffle: dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    dst.insert(2, 'FP_P', dst['FP'] )  \n",
    "    elapsed_time = float(time.time() - start)\n",
    "    print(\"data read - {} - time:{}\" .format(len(dst), elapsed_time ))\n",
    "\n",
    "    # #dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "    # if batch_size > spn: spn = -1\n",
    "    # dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    # dataT  = {'label' : dst.loc[spn:,'FP_P'] , 'data' :  dst.iloc[spn:, 3:] }\n",
    "    # dataE  = {'label' : dst.loc[:spn-1,'FP_P'] , 'data' :  dst.iloc[:spn, 3:] }\n",
    "    #print(\"data read - lenTrain={}-{} & lenEv={}-{} time:{}\" .format(len(dataT[\"data\"]), \n",
    "    #    len(dataT[\"label\"]),len(dataE[\"data\"]),len(dataE[\"label\"]), elapsed_time ))\n",
    "    # dataT= convert_2List(dataT)\n",
    "    # dataE= convert_2List(dataE)\n",
    "    \n",
    "def get_batches(batch_size):\n",
    "    n_batches = int(len( dst.loc[spn:]  ) // batch_size)\n",
    "    print(n_batches*batch_size)\n",
    "    # x,y = dataT[\"data\"][:n_batches*batch_size], dataT[\"label\"][:n_batches*batch_size]\n",
    "    for ii in range(0, len( dst.loc[spn:spn+n_batches*batch_size]) , batch_size ):\n",
    "        #convert to list! \n",
    "        yield dst.iloc[spn+ii: spn+ii+batch_size, 3:].as_matrix().tolist(), dst.loc[spn+ii: spn+ii+batch_size-1, 'FP_P' ].as_matrix().tolist() \n",
    "        \n",
    "def check_perf_CN(predv, dataEv, sk_ev=False ):\n",
    "    gt3 = 0; gtM = 0; \n",
    "    # predvList = predv.tolist()\n",
    "    # assert(len(predv) == len(dataEv['label']))\n",
    "    print(\"denormalization all Evaluation : {} = {}\" .format(len(predv[1]), len(dataEv)))\n",
    "    #for i in range(100):\n",
    "    for i in range(len(dataEv)):\n",
    "        if (i % 1000==0): print(str(i)) #, end=\"__\") \n",
    "        try:\n",
    "            # pred_v = dc( predv.tolist()[i], np.max(predv[i]))\n",
    "            pred_v = predv[1][i][0]\n",
    "            data_v = dataEv[i] if sk_ev  else dc( dataEv[i])\n",
    "            if   dType == 'C4' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C2' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C1':\n",
    "                num = abs(pred_v-data_v)\n",
    "                if num > 3: gt3+=1\n",
    "                if num > 10: gtM+=1\n",
    "        except: print(\"error: i={}, pred={}, data={} -- \".format(i, pred_v, data_v))\n",
    "    print(\"Total: {} GT3: {}  GTM: {}\".format(len(predv[1]), gt3, gtM)) \n",
    "    return gt3, gtM \n",
    "def feed_data(dataJJ, p_abs, d_st = False, p_exp=False, pand=False, p_col = False):\n",
    "    indx=[];   index_col=0 if p_abs else 2 #abs=F => 2 == 6D\n",
    " \n",
    "    # col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = col_df.fillna(0)\n",
    "    print(\"input-no={}\".format( len(col_df )))\n",
    "    \n",
    "    if p_exp:   indx.append(i for i in range(103))\n",
    "    else:       indx = col_df.index\n",
    "    \n",
    "    if p_col: \n",
    "        dataTest_label = []\n",
    "        dataJJ = \"[\"\n",
    "        for i in range(len(col_df)): \n",
    "            dataTest_label.append( cc( int(  col_df.iloc[i][\"fp\"]  )  )) \n",
    "            dataJJ += '{\"m\":\"'+str(i)+'\",'+'\"'+str(col_df.iloc[i].name)+'\"'+\":1},\"\n",
    "        dataJJ += '{\"m\":\"0\"}]';  dataTest_label.append(cc(0))\n",
    "        # dataJJ += ']'\n",
    "        dataJJ = json.loads(dataJJ)\n",
    "\n",
    "    json_df  = pd.DataFrame(columns=indx); df_entry = pd.Series(index=indx)\n",
    "    df_entry = df_entry.fillna(0) \n",
    "   \n",
    "    ccount = Counter()\n",
    "    if(isinstance(dataJJ, list)):json_data = dataJJ\n",
    "    else: json_str=open(dataJJ).read();  json_data = json.loads(json_str)\n",
    "    # for i in range(20):\n",
    "    for i in range(len(json_data)): # print(i)\n",
    "        df_entry *= 0\n",
    "        m = str(json_data[i][\"m\"])\n",
    "        df_entry.name = m\n",
    "        for key in json_data[i]:\n",
    "            if key == \"m\": pass            \n",
    "            else: \n",
    "                key_wz = key if p_abs else (int(key))  #str(int(key)) FRFLO - int // FRALL str!\n",
    "                try: #filling of key - experimental or COMP \n",
    "                    ds_comp = col_df.loc[key_wz]\n",
    "                    if p_exp == True:  #fp key - 0-102   \n",
    "                        co = str(ds_comp['FP'])\n",
    "                        if co == 'nan':  col_key = 102\n",
    "                        else: \n",
    "                            col_key = int(ds_comp['FP'])\n",
    "                            if col_key>101: col_key = 101\n",
    "                            if col_key<0: col_key = 0\n",
    "                    else: col_key = key_wz      \n",
    "                    # df_entry.loc[col_key]\n",
    "                    df_entry[col_key] =  np.float32(json_data[i][key])\n",
    "                except: \n",
    "                    if d_st: print(\"m:{}-c:{} not included\" .format(m, key_wz)); ccount[key_wz] +=1\n",
    "\n",
    "        json_df = json_df.append(df_entry,ignore_index=False)\n",
    "        if i % 1000 == 0: print(\"cycle: {}\".format(i))\n",
    "    print(\"Counter of comp. not included :\"); print(ccount) # print(len(ccount))\n",
    "\n",
    "    if p_col: return json_df.as_matrix().tolist(), dataTest_label\n",
    "    else: \n",
    "        if pand:  return json_df  \n",
    "        else:     return json_df.as_matrix().tolist() \n",
    "#---------------------------------------------------------------------\n",
    "print(\"data manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "#     print(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG        = \"../../_zfp/LOG.txt\"\n",
    "LOGDIR     = \"../../_zfp/data/my_graph/\"\n",
    "LOGDAT     = \"../../_zfp/data/\"\n",
    "\n",
    "# spn        = 5000  #5000 -1 = all for training \n",
    "spn = 1\n",
    "# DESC       = \"ZTEST\"\n",
    "DESC       = \"FRFLO\"\n",
    "# DESC       = \"FRALL1\"\n",
    "dType      = \"C1\" #C1 or C4\n",
    "MMF        = \"MODJJ1\" #2(1) OR 5 (4)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "MODEL_DIR  = LOGDIR + DESC + '/' + DESC + dType +  MMF +\"/\"  \n",
    "model_path = MODEL_DIR + \"model.ckpt\" \n",
    "DSJ        = \"/data_json.txt\"\n",
    "DSC        = \"/datasc.csv\"   \n",
    "DC         = \"/datac.csv\"\n",
    "DL         = \"/datal.csv\"\n",
    "LAB_DS     = LOGDAT + DESC + DL #\"../../_zfp/data/FRFLO/datal.csv\"\n",
    "COL_DS     = LOGDAT + DESC + DC \n",
    "ALL_DSJ    = LOGDAT + DESC + DSJ \n",
    "ALL_DS     = LOGDAT + DESC + DSC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read - 9610 - time:5.398799896240234\n",
      "9610\n"
     ]
    }
   ],
   "source": [
    "mainRead2(ALL_DS, 1, 2, all = True, shuffle = True  ) \n",
    "print(len(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst.describe()\n",
    "# dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# get the indices of the array where it is not zero\n",
    "dst.iloc[0].nonzero()\n",
    "ds =  dst.iloc[0]\n",
    "# print(ds)\n",
    "print(len(ds.iloc[ds.nonzero()]))\n",
    "ds.iloc[ds.nonzero()]\n",
    "\n",
    "# I will need this for the embedding - but this means I will not be able to use batch - 128; \n",
    "# I will have to process every input individually\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Network  <a id=\"model\"></a> \n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------------------------\n",
    "def get_nns(): \n",
    "    #nns =  str(ninp)+'*'+str(h[0])+'*'+str(h[1])+'*'+str(nout)\n",
    "    nns =  str(ninp)+'*' \n",
    "    for i in range(len(h)):\n",
    "        nns = nns +str(h[i])+'*'\n",
    "    return nns +str(nout)\n",
    "def get_hpar(): return \"lr_%.0E_NN%s\" % (lr, get_nns())\n",
    "\n",
    "def logr(datep = '' , time='', it=1000, nn='', typ='TR', DS='', AC=0, num=0, AC3=0, AC10=0, desc='', startTime='', batch_size=128):\n",
    "    if desc == '': print(\"Log not recorded\"); return \n",
    "    LOG = \"../../_zfp/LOGT2.txt\"\n",
    "    f= open(LOG ,\"a+\") #w,a,\n",
    "    if datep != '':   dats = datep\n",
    "    else:             dats = datetime.now().strftime('%d.%m.%Y') \n",
    "    if time != '':    times = time\n",
    "    else:             times = datetime.now().strftime('%H:%M:%S') \n",
    "\n",
    "    line =  datetime.now().strftime('%d.%m.%Y') + '\\t' + times \n",
    "    line = line + '\\t' + str(it) + '\\t'+  get_nns() +  '\\t' + str(lr)\n",
    "    line = line + '\\t' + typ \n",
    "    line = line + '\\t' + str(DS) + '\\t' + str(AC) + '\\t' + str(num) + '\\t' + str(AC3) + '\\t' +  str(AC10) + '\\t' + desc \n",
    "    line = line + '\\t' + str(batch_size) + '\\t' +  startTime + '\\n' #new\n",
    "\n",
    "    f.write(line);  f.close()\n",
    "    print(\"___Log recorded\")    \n",
    "def restore_model(sess):   \n",
    "    saver= tf.train.Saver() \n",
    "    print(\"Model restored from file: %s\" % model_path)\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "# print(get_hpar())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "Name: FP_P, dtype: object\n",
      "4*50*102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs     = 10\n",
    "disp       = 5\n",
    "batch_s    = 64\n",
    "\n",
    "lr         = 0.001\n",
    "# h        = [50]\n",
    "h          = [100 , 40]\n",
    "# h          = [40 , 10]\n",
    "# h = [1000, 500, 250, 125]\n",
    "\n",
    "ninp  = len(dst.columns) - 3 \n",
    "\n",
    "if   dType == 'C4':  nout = 4;   \n",
    "elif dType == 'C1': nout = 102;\n",
    "    \n",
    "#def convert_2List(dst): return {'label' : dst[\"label\"].as_matrix().tolist(), 'data' : dst[\"data\"].as_matrix().tolist()}\n",
    "# dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "dst['FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "\n",
    "print(dst.loc[:10,'FP_P'])\n",
    "print( get_nns() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(inp, nodes, kp, is_train):\n",
    "    # h = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    h = tf.layers.dense( inp, nodes, use_bias=False, activation=None )\n",
    "    h = tf.layers.batch_normalization(h, training=is_train)\n",
    "    h = tf.nn.relu(h)\n",
    "    h = tf.nn.dropout(h, kp)\n",
    "    return h\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "def build_network2(is_train=False):     # Simple NN - with batch normalization (high level)\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    tf.reset_default_graph()\n",
    "    x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "    y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "    inp = x \n",
    "    for i in range(len(h)): \n",
    "        hx = fc(inp,  h[i], kp, is_train)\n",
    "        inp = hx \n",
    "#     h0  = fc(x,  h[0], kp, is_train)\n",
    "#     h1  = fc(h0, h[1], kp, is_train)\n",
    "    out = tf.layers.dense( hx, nout, use_bias=False, activation=None )\n",
    "    #out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    #out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # softmaxT = tf.nn.softmax(out)\n",
    "        softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "\n",
    "        prediction=tf.reduce_max(y,1)\n",
    "        correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    with tf.name_scope(\"xent\"): #loss!\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=out, labels=y))\n",
    "        tf.summary.scalar(\"xent\", cost)\n",
    "    with tf.name_scope(\"train\"): #opt!\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "    summ = tf.summary.merge_all()   \n",
    "    \n",
    "    return out, accuracy, softmaxT, x, y, optimizer, summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network built\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prediction, accuracy, softmaxT, x, y, optimizer, summ  = build_network2()\n",
    "print(\"network built\")\n",
    "\n",
    "\n",
    "saver= tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def build_network3(is_train=False):     # RNN - embeddings\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    \n",
    "    # I cannot use embeddings because they only allow int32 and int64\n",
    "    # but my data is in percentage - decimals ... - experiment \n",
    "    # embedding = tf.Variable(tf.random_uniform((ninp, h[0]), -1, 1))\n",
    "    # h0 = tf.nn.embedding_lookup(embedding, x)\n",
    "    # h0 = tf.gather(embedding, x)\n",
    "\n",
    "    #only solution: \n",
    "    # - Train: \n",
    "    #index = dst[i].nonzero()\n",
    "    #for j in index:\n",
    "    #    wtemp.append(w0[j]) \n",
    "    #    xtmp.append(dst[i].iloc[j])\n",
    "    #wtemp.dot(xtmp)  \n",
    "    #run optimize feed_dict h0: h0, y: y ... \n",
    "    \n",
    "    # h0 = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    # h0 = tf.layers.dense( x, h[0], use_bias=False, activation=None )\n",
    "    # h0 = tf.layers.batch_normalization(h0, training=is_train)\n",
    "    # h0 = tf.nn.relu(h0)\n",
    "    # h0 = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    h1 = tf.layers.dense( h0, h[1], use_bias=False, activation=None )\n",
    "    h1 = tf.layers.batch_normalization(h1, training=is_train)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    # h1 = tf.nn.dropout(h1, kp)\n",
    "    \n",
    "    out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "    out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    " \n",
    "    # softmaxT = tf.nn.softmax(out)\n",
    "    softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "            \n",
    "    prediction=tf.reduce_max(y,1)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return out, accuracy, softmaxT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAN built\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "        return out   \n",
    "    \n",
    "extra_class = 0        \n",
    "def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(x, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        class_logits  = tf.layers.dense( h1, nout+extra_class, use_bias=False, activation=None )\n",
    "        # out = tf.layers.batch_normalization(out, training=is_train)\n",
    "        # out = tf.nn.relu(out)\n",
    "        # out = tf.nn.dropout(out, kp)\n",
    "\n",
    "        if extra_class:\n",
    "            real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "            fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "        else:\n",
    "            real_class_logits = class_logits\n",
    "            fake_class_logits = 0.\n",
    "            \n",
    "        mx = tf.reduce_max(real_class_logits, 1, keep_dims=True)\n",
    "        stable_real_class_logits = real_class_logits - mx\n",
    "        gan_logits = tf.log(tf.reduce_sum(tf.exp(stable_real_class_logits), 1)) + tf.squeeze(mx) - fake_class_logits\n",
    "        out = tf.nn.softmax(class_logits)\n",
    "        return out, class_logits, gan_logits, features\n",
    "        \n",
    "def model_loss(input_real, input_z, output_dim, y, num_classes, label_mask, alpha=0.2, drop_rate=0.):\n",
    "    g_size_mult = 32\n",
    "    d_size_mult = 64\n",
    "    \n",
    "    g_model = generator(input_z, output_dim, alpha=alpha, size_mult=g_size_mult)\n",
    "    d_on_data = discriminator(input_real, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_real, class_logits_on_data, gan_logits_on_data, data_features = d_on_data\n",
    "    d_on_samples = discriminator(g_model, reuse=True, alpha=alpha, drop_rate=drop_rate, size_mult=d_size_mult)\n",
    "    d_model_fake, class_logits_on_samples, gan_logits_on_samples, sample_features = d_on_samples\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return d_loss, g_loss, correct, masked_correct, g_model\n",
    "\n",
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    for t in t_vars:\n",
    "        assert t in d_vars or t in g_vars\n",
    "    d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "    g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "    shrink_lr = tf.assign(learning_rate, learning_rate * 0.9)\n",
    "    return d_train_opt, g_train_opt, shrink_lr\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self, real_size, z_size, learning_rate, num_classes=10, alpha=0.2, beta1=0.5):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.learning_rate = tf.Variable(learning_rate, trainable=False)\n",
    "        self.input_real, self.input_z, self.y, self.label_mask = model_inputs(real_size, z_size)\n",
    "        self.drop_rate = tf.placeholder_with_default(.5, (), \"drop_rate\")\n",
    "        \n",
    "        loss_results = model_loss(self.input_real, self.input_z,\n",
    "                                    real_size[2], self.y, num_classes, label_mask=self.label_mask, alpha=0.2,\n",
    "                                    drop_rate=self.drop_rate) \n",
    "        \n",
    "        self.d_loss, self.g_loss, self.correct, self.masked_correct, self.samples = loss_results       \n",
    "        \n",
    "        self.d_opt, self.g_opt, self.shrink_lr = model_opt(self.d_loss, self.g_loss, self.learning_rate, beta1)\n",
    "        \n",
    "\n",
    "# real_size = (32,32,3)\n",
    "# z_size = 100\n",
    "# learning_rate = 0.0003\n",
    "\n",
    "# # net = GAN(real_size, z_size, learning_rate)\n",
    "\n",
    "# x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "# z = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"z\")\n",
    "# y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "# lm= tf.placeholder(tf.int32, (None), name='label_mask')\n",
    "print(\"GAN built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network1 - TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def train(it = 100, disp=50, batch_size = 128):    \n",
    "    print(\"____TRAINING...\") #dst.loc[spn:,'FP_P'] dst.iloc[spn:, 3:]  \n",
    "    display_step =  disp \n",
    "\n",
    "    dataTest = {'label' : [] , 'data' :  [] };\n",
    "    #dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    \n",
    "    #dataT['data'].append(dataTest['data']) ;     md.dataT['label'].append(dataTest['label']) \n",
    "    print(\"data read - lenTrain={}-{} \" .format(len(dataTest[\"data\"]), len(dataTest[\"label\"]) ))\n",
    "\n",
    "    total_batch  = int(len(dst.loc[spn:]) / batch_size)\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # restore_model(sess)  #Run if I want to retrain an existing model\n",
    "        writer = tf.summary.FileWriter(MODEL_DIR+\"tboard/\", sess.graph )\n",
    "        \n",
    "        start = time.time()\n",
    "        for i in range(it):            \n",
    "            for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "                # xtb, ytb = dc.next_batch(batch_size, dataT['data'], dataT['label'])\n",
    "                sess.run(optimizer, feed_dict={x: xtb, y: ytb})\n",
    "                if ii % display_step ==0: #record_step == 0:\n",
    "                    [train_accuracy] = sess.run([accuracy], feed_dict={x: xtb, y: ytb }) \n",
    "                    #s = sess.run(summ, feed_dict={x: xtb, y: ytb })\n",
    "                    #[train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: xtb, y: ytb }) \n",
    "                    #writer.add_summary(s, i)\n",
    "                    \n",
    "                    elapsed_time = float(time.time() - start)\n",
    "                    reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "                    rp_s = str(reviews_per_second)[0:5]\n",
    "                    tr_ac = str(train_accuracy)[:5]  \n",
    "                    print('Epoch: {} batch: {} / {} - %Speed(it/disp_step): {} - tr_ac {}' .format(i, ii, total_batch, rp_s, tr_ac ))\n",
    "                    \n",
    "            #sess.run(optimizer, feed_dict={x: dataTest['data'], y: dataTest['label']})\n",
    "            #[train_accuracy] = sess.run([accuracy], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "            #print(\"ColC-{}\".format(train_accuracy))\n",
    "            \n",
    "            #ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5]            \n",
    "            test_accuracy = sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  })\n",
    "            ev_ac = str(test_accuracy)[:5]            \n",
    "            print(\"E Ac:\", ev_ac)\n",
    "\n",
    "            #tr_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()   }) )[:5]  \n",
    "            train_accuracy = sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()   })\n",
    "            tr_ac = str( train_accuracy )[:5] \n",
    "            print(\"T Ac:\", tr_ac)\n",
    "        \n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        \n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    logr( it=it, typ='TR', DS=DESC, AC=tr_ac,num=len(dst)-spn, AC3=0, AC10=0, desc=des(), startTime=startTime, batch_size=batch_size )\n",
    "    logr( it=it, typ='EV', DS=DESC, AC=ev_ac,num=spn , AC3=0, AC10=0, desc=des() )\n",
    "#---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print(type(dst.iloc[:spn-1,2:3]))\n",
    "# test = dst.loc[:2, 'FP_P']\n",
    "# print(type(test.tolist()))\n",
    "# test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate( ): \n",
    "    print(\"_____EVALUATION...\")\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        tr_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()    }) )[:5]  \n",
    "        ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5] \n",
    "        print(\"Training   Accuracy:\", tr_ac )\n",
    "        print(\"Evaluation Accuracy:\", ev_ac )\n",
    "        predv, softv = sess.run([prediction, softmaxT], feed_dict={x: dst.iloc[:spn, 3:]  }) # , y: md.dataE['label'] \n",
    "        # maxa = sess.run([prediction], feed_dict={y: predv })\n",
    "    print(\"Preview the first predictions:\")\n",
    "    for i in range(20):\n",
    "        print(\"RealVal: {}  - PP value: {}\".format( dc( dst.loc[:spn-1,'FP_P'][i])   , \n",
    "                                                    dc( predv.tolist()[i], np.max(predv[i]))  ))\n",
    "    gt3, gtM = check_perf_CN(softv, dst.loc[:spn-1,'FP_P'], False)\n",
    "    logr(  it=0, typ='EV', AC=ev_ac,DS=DESC, num=spn, AC3=gt3, AC10=gtM, desc=des(), startTime=startTime, batch_size=batch_s )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tests(url_test = 'url', p_col=False):  \n",
    "    print(\"_____TESTS...\")    \n",
    "    global DESC\n",
    "    # Load test data \n",
    "    dataTest = {'label' : [] , 'data' :  [] }; pred_val = []\n",
    "    if p_col: dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    else: \n",
    "        if url_test != 'url':  \n",
    "            json_data = url_test + \"data_json6.txt\"\n",
    "            tmpLab = pd.read_csv(url_test + \"datal6.csv\", sep=',', usecols=[0,1])    \n",
    "            tmpLab = tmpLab.loc[:,'fp']\n",
    "            abstcc = False\n",
    "        else: \n",
    "            #json_str, tmpLab = get_data_test(\"FRALL\")\n",
    "            json_str = '''[\n",
    "                        { \"m\":\"z\", \"c1\" :0.25, \"c2\" :0.25, \"c3\" :0.25, \"c4\" :0.25 }] '''\n",
    "            tmpLab = [1]\n",
    "            json_data = json.loads(json_str)\n",
    "            abstcc = True\n",
    "            DESC =  'matnrList...'\n",
    "        \n",
    "        dataTest['data']  = feed_data(json_data, p_abs=abstcc , d_st=True)\n",
    "        \n",
    "        dataTest['label'] = []\n",
    "        [dataTest['label'].append( cc(x) ) for x in tmpLab ]\n",
    "    # Predict data \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        # predv = sess.run( prediction, feed_dict={x: dataTest['data']}) \n",
    "        ts_acn = '0'\n",
    "        ts_acn, predv, sf = sess.run( [accuracy, prediction, softmaxT], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "        ts_ac = str(ts_acn) \n",
    "        print(\"test ac = {}\".format(ts_ac))\n",
    "    # print(dataTest['label']);     print(sf)\n",
    "    range_ts = len(predv) if len(predv)<20 else 20\n",
    "    for i in range( range_ts ):\n",
    "        # print(\"RealVal: {}  - PP value: {}\".format( dc( dataTest['label'][i]), dc( predv.tolist()[i], np.max(predv[i]))  ))  \n",
    "        print(\"{} RealVal: {} - {} - PP: {} PR: {}\".format( i, dc( dataTest['label'][i]), sf[1][i][0],  sf[1][i], sf[0][i]   ))\n",
    "\n",
    "    # return\n",
    "    gt3, gtM = check_perf_CN(sf, dataTest[\"label\"], False)\n",
    "    logr( it=0, typ='TS', DS=DESC, AC=ts_acn ,num=len(dataTest[\"label\"]),  AC3=gt3, AC10=gtM, desc=des(), batch_size=batch_s )  \n",
    "\n",
    "    outfile = '../../_zfp/data/export2' \n",
    "    np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "    np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTIONS <a id=\"exec\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 18\n",
    "# print(\"  PP: {} PR: {} \". format(   sf[1][i], sf[0][i]    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____TRAINING...\n",
      "data read - lenTrain=0-0 \n",
      "0\n",
      "Epoch: 0 batch: 0 / 0 - %Speed(it/disp_step): 0.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 1 batch: 0 / 0 - %Speed(it/disp_step): 35.71 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 2 batch: 0 / 0 - %Speed(it/disp_step): 55.55 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 3 batch: 0 / 0 - %Speed(it/disp_step): 69.76 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 4 batch: 0 / 0 - %Speed(it/disp_step): 78.43 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 5 batch: 0 / 0 - %Speed(it/disp_step): 84.74 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 6 batch: 0 / 0 - %Speed(it/disp_step): 84.50 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 7 batch: 0 / 0 - %Speed(it/disp_step): 88.60 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 8 batch: 0 / 0 - %Speed(it/disp_step): 91.95 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 9 batch: 0 / 0 - %Speed(it/disp_step): 95.74 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 10 batch: 0 / 0 - %Speed(it/disp_step): 99.00 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 11 batch: 0 / 0 - %Speed(it/disp_step): 101.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 12 batch: 0 / 0 - %Speed(it/disp_step): 104.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 13 batch: 0 / 0 - %Speed(it/disp_step): 106.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 14 batch: 0 / 0 - %Speed(it/disp_step): 107.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 15 batch: 0 / 0 - %Speed(it/disp_step): 110.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 16 batch: 0 / 0 - %Speed(it/disp_step): 111.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 17 batch: 0 / 0 - %Speed(it/disp_step): 112.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 18 batch: 0 / 0 - %Speed(it/disp_step): 113.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 19 batch: 0 / 0 - %Speed(it/disp_step): 114.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 20 batch: 0 / 0 - %Speed(it/disp_step): 115.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 21 batch: 0 / 0 - %Speed(it/disp_step): 116.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 22 batch: 0 / 0 - %Speed(it/disp_step): 117.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 23 batch: 0 / 0 - %Speed(it/disp_step): 117.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 24 batch: 0 / 0 - %Speed(it/disp_step): 118.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 25 batch: 0 / 0 - %Speed(it/disp_step): 117.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 26 batch: 0 / 0 - %Speed(it/disp_step): 118.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 27 batch: 0 / 0 - %Speed(it/disp_step): 118.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 28 batch: 0 / 0 - %Speed(it/disp_step): 118.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 29 batch: 0 / 0 - %Speed(it/disp_step): 116.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 30 batch: 0 / 0 - %Speed(it/disp_step): 117.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 31 batch: 0 / 0 - %Speed(it/disp_step): 118.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 32 batch: 0 / 0 - %Speed(it/disp_step): 118.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 33 batch: 0 / 0 - %Speed(it/disp_step): 119.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 34 batch: 0 / 0 - %Speed(it/disp_step): 120.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 35 batch: 0 / 0 - %Speed(it/disp_step): 120.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 36 batch: 0 / 0 - %Speed(it/disp_step): 121.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 37 batch: 0 / 0 - %Speed(it/disp_step): 120.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 38 batch: 0 / 0 - %Speed(it/disp_step): 120.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 39 batch: 0 / 0 - %Speed(it/disp_step): 120.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 40 batch: 0 / 0 - %Speed(it/disp_step): 121.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 41 batch: 0 / 0 - %Speed(it/disp_step): 121.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 42 batch: 0 / 0 - %Speed(it/disp_step): 122.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 43 batch: 0 / 0 - %Speed(it/disp_step): 122.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 44 batch: 0 / 0 - %Speed(it/disp_step): 123.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 45 batch: 0 / 0 - %Speed(it/disp_step): 123.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 46 batch: 0 / 0 - %Speed(it/disp_step): 123.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 47 batch: 0 / 0 - %Speed(it/disp_step): 124.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 48 batch: 0 / 0 - %Speed(it/disp_step): 124.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 49 batch: 0 / 0 - %Speed(it/disp_step): 125.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 50 batch: 0 / 0 - %Speed(it/disp_step): 125.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 51 batch: 0 / 0 - %Speed(it/disp_step): 125.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 52 batch: 0 / 0 - %Speed(it/disp_step): 125.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 53 batch: 0 / 0 - %Speed(it/disp_step): 124.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 54 batch: 0 / 0 - %Speed(it/disp_step): 124.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 55 batch: 0 / 0 - %Speed(it/disp_step): 123.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 56 batch: 0 / 0 - %Speed(it/disp_step): 122.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 57 batch: 0 / 0 - %Speed(it/disp_step): 122.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 58 batch: 0 / 0 - %Speed(it/disp_step): 123.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 59 batch: 0 / 0 - %Speed(it/disp_step): 123.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 60 batch: 0 / 0 - %Speed(it/disp_step): 121.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 61 batch: 0 / 0 - %Speed(it/disp_step): 122.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 62 batch: 0 / 0 - %Speed(it/disp_step): 122.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 63 batch: 0 / 0 - %Speed(it/disp_step): 122.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 64 batch: 0 / 0 - %Speed(it/disp_step): 122.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 65 batch: 0 / 0 - %Speed(it/disp_step): 122.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 66 batch: 0 / 0 - %Speed(it/disp_step): 122.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 67 batch: 0 / 0 - %Speed(it/disp_step): 123.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 68 batch: 0 / 0 - %Speed(it/disp_step): 123.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 69 batch: 0 / 0 - %Speed(it/disp_step): 123.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 70 batch: 0 / 0 - %Speed(it/disp_step): 124.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 71 batch: 0 / 0 - %Speed(it/disp_step): 124.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 72 batch: 0 / 0 - %Speed(it/disp_step): 124.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 73 batch: 0 / 0 - %Speed(it/disp_step): 124.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 74 batch: 0 / 0 - %Speed(it/disp_step): 124.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 75 batch: 0 / 0 - %Speed(it/disp_step): 125.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 76 batch: 0 / 0 - %Speed(it/disp_step): 125.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 77 batch: 0 / 0 - %Speed(it/disp_step): 125.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 78 batch: 0 / 0 - %Speed(it/disp_step): 125.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 79 batch: 0 / 0 - %Speed(it/disp_step): 125.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 80 batch: 0 / 0 - %Speed(it/disp_step): 125.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 81 batch: 0 / 0 - %Speed(it/disp_step): 125.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 82 batch: 0 / 0 - %Speed(it/disp_step): 125.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 83 batch: 0 / 0 - %Speed(it/disp_step): 125.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 84 batch: 0 / 0 - %Speed(it/disp_step): 125.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 85 batch: 0 / 0 - %Speed(it/disp_step): 126.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 86 batch: 0 / 0 - %Speed(it/disp_step): 126.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 87 batch: 0 / 0 - %Speed(it/disp_step): 126.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 88 batch: 0 / 0 - %Speed(it/disp_step): 126.8 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 89 batch: 0 / 0 - %Speed(it/disp_step): 126.9 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 90 batch: 0 / 0 - %Speed(it/disp_step): 127.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 91 batch: 0 / 0 - %Speed(it/disp_step): 127.2 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 92 batch: 0 / 0 - %Speed(it/disp_step): 127.6 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 93 batch: 0 / 0 - %Speed(it/disp_step): 127.7 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 94 batch: 0 / 0 - %Speed(it/disp_step): 128.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 95 batch: 0 / 0 - %Speed(it/disp_step): 128.0 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 96 batch: 0 / 0 - %Speed(it/disp_step): 128.1 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 97 batch: 0 / 0 - %Speed(it/disp_step): 128.3 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 98 batch: 0 / 0 - %Speed(it/disp_step): 128.4 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n",
      "0\n",
      "Epoch: 99 batch: 0 / 0 - %Speed(it/disp_step): 128.5 - tr_ac 1.0\n",
      "E Ac: 1.0\n",
      "T Ac: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/model.ckpt\n",
      "Optimization Finished!\n",
      "___Log recorded\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "epochs     = 100\n",
    "train_accuracies, test_accuracies = [], []\n",
    "train(epochs, disp, batch_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____EVALUATION...\n",
      "Model restored from file: ../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/model.ckpt\n",
      "Training   Accuracy: 1.0\n",
      "Evaluation Accuracy: 1.0\n",
      "Preview the first predictions:\n",
      "RealVal: 75  - PP value: 75\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-19bf740bcbf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mDESC\u001b[0m       \u001b[1;33m=\u001b[0m \u001b[1;34m\"FRFLO\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-560edd8b76d8>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Preview the first predictions:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         print(\"RealVal: {}  - PP value: {}\".format( dc( dst.loc[:spn-1,'FP_P'][i])   , \n\u001b[0m\u001b[0;32m     17\u001b[0m                                                     dc( predv.tolist()[i], np.max(predv[i]))  ))\n\u001b[0;32m     18\u001b[0m     \u001b[0mgt3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgtM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_perf_CN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mspn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FP_P'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a604080\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\a604080\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2475\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2477\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4404)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4087)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5126)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:14031)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13975)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "evaluate( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____TESTS...\n",
      "input-no=4\n",
      "cycle: 0\n",
      "Counter of comp. not included :\n",
      "Counter()\n",
      "Model restored from file: ../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/ZTEST/ZTESTC1MODJJ1/model.ckpt\n",
      "test ac = 0.0\n",
      "0 RealVal: 1 - 75 - PP: [75 20 25 52] PR: [  1.00000000e+00   7.28385341e-31   2.50849013e-31   1.70492173e-31]\n",
      "denormalization all Evaluation : 1 = 1\n",
      "0\n",
      "Total: 1 GT3: 1  GTM: 1\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "url_test = \"../../_zfp/data/FREXP1/\" ; DESC     = \"FREXP1_6\"\n",
    "\n",
    "url_test = \"url\"\n",
    "tests(url_test, p_col=False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhr4kNeT/A7tzxgxzT+oPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2dc588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_accuracies, label='Train', alpha=0.5)\n",
    "plt.plot(test_accuracies, label='Test', alpha=0.5)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding by FAM\n",
    "get data / get FAM <br>\n",
    "if am > 0 => 1; lookup tab.  => visualization embeddings in script. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logic... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# outfile = '../../_zfp/data/export.xlsx' \n",
    "\n",
    "# workbook   = xlsxwriter.Workbook(outfile)\n",
    "# worksheet1 = workbook.add_worksheet()\n",
    "# worksheet1.write('A1', 'M')\n",
    "# worksheet1.write(0, 0, 'Hello')  \n",
    "# for i in range(len(sf[0])):\n",
    "#     worksheet1.write(0, i , sf[0][i])  \n",
    "#     worksheet1.write(1, i , sf[1][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# outfile = '../../_zfp/data/export.csv' \n",
    "# f2= open(outfile,\"a+\")\n",
    "# output_writer = csv.writer(f2, delimiter=\"\\t\")\n",
    "# output_writer.writerows(sf)\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = '../../_zfp/data/export2' \n",
    "# np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "# np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display visualizations <a id=\"disp\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = outfile = '../../_zfp/data/FRFLO/datasc.csv' \n",
    "# dst  =  pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\")\n",
    "Y  = dst.loc[:,'FP'].as_matrix().tolist()\n",
    "X  = dst.loc[:, 'M'].as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1423b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 - Create plot. \n",
    "a = 1\n",
    "if a == 0: \n",
    "    plt.hist(Y)\n",
    "else: \n",
    "    plt.xlabel('M')\n",
    "    plt.ylabel('FP')\n",
    "    plt.grid(True)\n",
    "    N = 2 #50\n",
    "    colors = np.random.rand(N)\n",
    "    area = 1 #np.pi * (15 * np.random.rand(N))**2  # 0 to 15 point radii\n",
    "\n",
    "    #plt.plot(X, Y, color='blue', marker='o', label='FP Comp')\n",
    "    #plt.plot(X, Y, 'bo', label='FP Comp')\n",
    "    plt.scatter(X,Y, s=6, c='b', marker='o', cmap=None, norm=None, vmin=60, vmax=101, alpha=None,  label='FP Comp')\n",
    "    # plt.plot(X, Y,  s=area, c=colors, alpha=0.5) #'bo', label='FP Comp',\n",
    "    plt.legend()\n",
    "\n",
    "# 3 - Display plot. \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
