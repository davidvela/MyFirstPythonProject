{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FP\n",
    "\n",
    "## v2 - softmax 2, pandas, \n",
    "## next v3 - GAN , embeddings and visualization:  tensorboard and ...matplot\n",
    "\n",
    "Start writing all my logic in jupyter notebook in order to run them from anaconda! <br>\n",
    "** IMPORTANT ** <br>\n",
    "the network cell should only be intialize once! otherwise the program start creating indexes for the variables!!!! \n",
    "\n",
    "tensorboard --logdir=.\\my_graph\t\n",
    "tensorboard => http://localhost:6006 <br>\n",
    "jupyter => http://localhost:8889\n",
    "\n",
    "## index: \n",
    "<a id='index'/>\n",
    "\n",
    "1. READ DATA \n",
    "    * Class \n",
    "    * files \n",
    "2. [Network](#model)\n",
    "3. [execution](#exec) \n",
    "4. [display](#disp)\n",
    "\n",
    "\n",
    "other: \n",
    "4. [Evaluate](#ev) \n",
    "5. [Test](#ts) \n",
    "6. [Other](#o)\n",
    "\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from types import *\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1511132726.9796767"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:05:27'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=.\\mygraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data manipulation\n"
     ]
    }
   ],
   "source": [
    "def des():  return DESC+'_'+dType #+\"_filt:\"+  filter[0]+str(filter[1])\n",
    "def c2(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 60 ):                  return [1,0]  \n",
    "        elif( df >= 60 ):               return [0,1]      \n",
    "    elif rf==2: \n",
    "        if( df < 60 ):                  return 0\n",
    "        elif( df >= 60 ):               return 1\n",
    "def c4(df, rv=1):\n",
    "    if rv == 1:\n",
    "        if( df < 23 ):                  return [1,0,0,0]  #0\n",
    "        elif( df >= 23 and df < 60 ):   return [0,1,0,0]  #1\n",
    "        elif( df >= 60 and df < 93 ):   return [0,0,1,0]  #2\n",
    "        elif( df >= 93 ):               return [0,0,0,1]  #3    \n",
    "    elif rf==2: \n",
    "        if( df < 23 ):                  return 0\n",
    "        elif( df >= 23 and df < 60 ):   return 1\n",
    "        elif( df >= 60 and df < 93 ):   return 2\n",
    "        elif( df >= 93 ):               return 3\n",
    "    # elif rf==3: \n",
    "    #     if  ( df == [1,0,0,0] ):        return 0 \n",
    "    #     elif( df == [0,1,0,0] ):        return 1\n",
    "    #     elif( df == [0,0,1,0] ):        return 2  \n",
    "    #     elif( df == [0,0,0,1] ):        return 3  \n",
    "def cN(df):\n",
    "    global nout\n",
    "    listofzeros = [0] * nout\n",
    "    dfIndex = df #//nRange\n",
    "    # print('{} and {}', (df,dfIndex))\n",
    "    if    0 < dfIndex < nout:   listofzeros[dfIndex] = 1\n",
    "    elif  dfIndex < 0:          listofzeros[0]       = 1\n",
    "    elif  dfIndex >= nout:      listofzeros[nout-1]  = 1\n",
    "    \n",
    "    return listofzeros \n",
    "def cc(x, rv=1):\n",
    "    global nout\n",
    "    if   dType == 'C4':  return c4(x, rv);\n",
    "    elif dType == 'C1':  return cN(x); \n",
    "    elif dType == 'C2':  nout = 2;   return c2(x, rv);\n",
    "def dc(df, val = 1 ):    return df.index(val)  \n",
    "def normalize():     dst[:, 'FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "def mainRead2( path, part, batch_size , all = True, shuffle = True):  \n",
    "    # read by partitions!   \n",
    "    global  spn, dst;\n",
    "    start = time.time()\n",
    "    if all:  dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" )\n",
    "    else:     \n",
    "        columns = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=0, nrows=1)\n",
    "        dst = pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\" ,skiprows=part*batch_size+1, \n",
    "                           nrows=batch_size, names = columns.columns)\n",
    "    \n",
    "    dst = dst.fillna(0)\n",
    "    if shuffle: dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    dst.insert(2, 'FP_P', dst['FP'] )  \n",
    "    elapsed_time = float(time.time() - start)\n",
    "    print(\"data read - {} - time:{}\" .format(len(dst), elapsed_time ))\n",
    "\n",
    "    # #dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "    # if batch_size > spn: spn = -1\n",
    "    # dst = dst.sample(frac=1).reset_index(drop=True) \n",
    "    # dataT  = {'label' : dst.loc[spn:,'FP_P'] , 'data' :  dst.iloc[spn:, 3:] }\n",
    "    # dataE  = {'label' : dst.loc[:spn-1,'FP_P'] , 'data' :  dst.iloc[:spn, 3:] }\n",
    "    #print(\"data read - lenTrain={}-{} & lenEv={}-{} time:{}\" .format(len(dataT[\"data\"]), \n",
    "    #    len(dataT[\"label\"]),len(dataE[\"data\"]),len(dataE[\"label\"]), elapsed_time ))\n",
    "    # dataT= convert_2List(dataT)\n",
    "    # dataE= convert_2List(dataE)\n",
    "    \n",
    "def get_batches(batch_size):\n",
    "    n_batches = int(len( dst.loc[spn:]  ) // batch_size)\n",
    "    print(n_batches*batch_size)\n",
    "    # x,y = dataT[\"data\"][:n_batches*batch_size], dataT[\"label\"][:n_batches*batch_size]\n",
    "    for ii in range(0, len( dst.loc[spn:spn+n_batches*batch_size]) , batch_size ):\n",
    "        #convert to list! \n",
    "        yield dst.iloc[spn+ii: spn+ii+batch_size, 3:].as_matrix().tolist(), dst.loc[spn+ii: spn+ii+batch_size-1, 'FP_P' ].as_matrix().tolist() \n",
    "        \n",
    "def check_perf_CN(predv, dataEv, sk_ev=False ):\n",
    "    gt3 = 0; gtM = 0; \n",
    "    # predvList = predv.tolist()\n",
    "    # assert(len(predv) == len(dataEv['label']))\n",
    "    print(\"denormalization all Evaluation : {} = {}\" .format(len(predv[1]), len(dataEv)))\n",
    "    #for i in range(100):\n",
    "    for i in range(len(dataEv)):\n",
    "        if (i % 1000==0): print(str(i)) #, end=\"__\") \n",
    "        try:\n",
    "            # pred_v = dc( predv.tolist()[i], np.max(predv[i]))\n",
    "            pred_v = predv[1][i][0]\n",
    "            data_v = dataEv[i] if sk_ev  else dc( dataEv[i])\n",
    "            if   dType == 'C4' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C2' and pred_v != data_v:  gt3=gtM=gtM+1\n",
    "            elif dType == 'C1':\n",
    "                num = abs(pred_v-data_v)\n",
    "                if num > 3: gt3+=1\n",
    "                if num > 10: gtM+=1\n",
    "        except: print(\"error: i={}, pred={}, data={} -- \".format(i, pred_v, data_v))\n",
    "    print(\"Total: {} GT3: {}  GTM: {}\".format(len(predv[1]), gt3, gtM)) \n",
    "    return gt3, gtM \n",
    "def feed_data(dataJJ, p_abs, d_st = False, p_exp=False, pand=False, p_col = False):\n",
    "    indx=[];   index_col=0 if p_abs else 2 #abs=F => 2 == 6D\n",
    " \n",
    "    # col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = col_df.fillna(0)\n",
    "    print(\"input-no={}\".format( len(col_df )))\n",
    "    \n",
    "    if p_exp:   indx.append(i for i in range(103))\n",
    "    else:       indx = col_df.index\n",
    "    \n",
    "    if p_col: \n",
    "        dataTest_label = []\n",
    "        dataJJ = \"[\"\n",
    "        for i in range(len(col_df)): \n",
    "            dataTest_label.append( cc( int(  col_df.iloc[i][\"fp\"]  )  )) \n",
    "            dataJJ += '{\"m\":\"'+str(i)+'\",'+'\"'+str(col_df.iloc[i].name)+'\"'+\":1},\"\n",
    "        dataJJ += '{\"m\":\"0\"}]';  dataTest_label.append(cc(0))\n",
    "        # dataJJ += ']'\n",
    "        dataJJ = json.loads(dataJJ)\n",
    "\n",
    "    json_df  = pd.DataFrame(columns=indx); df_entry = pd.Series(index=indx)\n",
    "    df_entry = df_entry.fillna(0) \n",
    "   \n",
    "    ccount = Counter()\n",
    "    if(isinstance(dataJJ, list)):json_data = dataJJ\n",
    "    else: json_str=open(dataJJ).read();  json_data = json.loads(json_str)\n",
    "    # for i in range(20):\n",
    "    for i in range(len(json_data)): # print(i)\n",
    "        df_entry *= 0\n",
    "        m = str(json_data[i][\"m\"])\n",
    "        df_entry.name = m\n",
    "        for key in json_data[i]:\n",
    "            if key == \"m\": pass            \n",
    "            else: \n",
    "                key_wz = key if p_abs else (int(key))  #str(int(key)) FRFLO - int // FRALL str!\n",
    "                try: #filling of key - experimental or COMP \n",
    "                    ds_comp = col_df.loc[key_wz]\n",
    "                    if p_exp == True:  #fp key - 0-102   \n",
    "                        co = str(ds_comp['FP'])\n",
    "                        if co == 'nan':  col_key = 102\n",
    "                        else: \n",
    "                            col_key = int(ds_comp['FP'])\n",
    "                            if col_key>101: col_key = 101\n",
    "                            if col_key<0: col_key = 0\n",
    "                    else: col_key = key_wz      \n",
    "                    # df_entry.loc[col_key]\n",
    "                    df_entry[col_key] =  np.float32(json_data[i][key])\n",
    "                except: \n",
    "                    if d_st: print(\"m:{}-c:{} not included\" .format(m, key_wz)); ccount[key_wz] +=1\n",
    "\n",
    "        json_df = json_df.append(df_entry,ignore_index=False)\n",
    "        if i % 1000 == 0: print(\"cycle: {}\".format(i))\n",
    "    print(\"Counter of comp. not included :\"); print(ccount) # print(len(ccount))\n",
    "\n",
    "    if p_col: return json_df.as_matrix().tolist(), dataTest_label\n",
    "    else: \n",
    "        if pand:  return json_df  \n",
    "        else:     return json_df.as_matrix().tolist() \n",
    "#---------------------------------------------------------------------\n",
    "print(\"data manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "#     print(ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Pandas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LOG        = \"../../_zfp/LOG.txt\"\n",
    "LOGDIR     = \"../../_zfp/data/my_graph/\"\n",
    "LOGDAT     = \"../../_zfp/data/\"\n",
    "\n",
    "spn        = 5000  #5000 -1 = all for training \n",
    "\n",
    "DESC       = \"FRFLO\"\n",
    "# DESC       = \"FRALL1\"\n",
    "dType      = \"C4\" #C1 or C4\n",
    "MMF        = \"MODJJ1\" #2(1) OR 5 (4)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "MODEL_DIR  = LOGDIR + DESC + '/' + DESC +  MMF +\"/\"  \n",
    "model_path = MODEL_DIR + \"model.ckpt\" \n",
    "DSJ        = \"/data_json.txt\"\n",
    "DSC        = \"/datasc.csv\"   \n",
    "DC         = \"/datac.csv\"\n",
    "DL         = \"/datal.csv\"\n",
    "LAB_DS     = LOGDAT + DESC + DL #\"../../_zfp/data/FRFLO/datal.csv\"\n",
    "COL_DS     = LOGDAT + DESC + DC \n",
    "ALL_DSJ    = LOGDAT + DESC + DSJ \n",
    "ALL_DS     = LOGDAT + DESC + DSC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read - 9610 - time:5.330427169799805\n",
      "9610\n"
     ]
    }
   ],
   "source": [
    "mainRead2(ALL_DS, 1, 2, all = True, shuffle = True  ) \n",
    "print(len(dst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>FP</th>\n",
       "      <th>FP_P</th>\n",
       "      <th>100023</th>\n",
       "      <th>100025</th>\n",
       "      <th>100028</th>\n",
       "      <th>100034</th>\n",
       "      <th>100041</th>\n",
       "      <th>100060</th>\n",
       "      <th>100061</th>\n",
       "      <th>...</th>\n",
       "      <th>964392</th>\n",
       "      <th>972612</th>\n",
       "      <th>978488</th>\n",
       "      <th>982437</th>\n",
       "      <th>982440</th>\n",
       "      <th>983685</th>\n",
       "      <th>983686</th>\n",
       "      <th>996041</th>\n",
       "      <th>998063</th>\n",
       "      <th>998168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9.610000e+03</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9.610000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9.610000e+03</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9.610000e+03</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9610.000000</td>\n",
       "      <td>9.610000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>601962.775963</td>\n",
       "      <td>87.214256</td>\n",
       "      <td>87.214256</td>\n",
       "      <td>1.968887e-09</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.974741e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>6.771072e-15</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>1.309067e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.040583e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>242149.031945</td>\n",
       "      <td>10.047519</td>\n",
       "      <td>10.047519</td>\n",
       "      <td>1.576348e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>9.868021e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>6.630585e-13</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.058937</td>\n",
       "      <td>8.014352e-06</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1.020090e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100456.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>394230.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>704052.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>777086.750000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>963939.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.500000e-05</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>6.250000e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>6.500000e-11</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>6.640130e-04</td>\n",
       "      <td>0.088571</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>1.000000e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   M           FP         FP_P        100023       100025  \\\n",
       "count    9610.000000  9610.000000  9610.000000  9.610000e+03  9610.000000   \n",
       "mean   601962.775963    87.214256    87.214256  1.968887e-09     0.000001   \n",
       "std    242149.031945    10.047519    10.047519  1.576348e-07     0.000037   \n",
       "min    100456.000000     5.000000     5.000000  0.000000e+00     0.000000   \n",
       "25%    394230.000000    82.000000    82.000000  0.000000e+00     0.000000   \n",
       "50%    704052.000000    89.000000    89.000000  0.000000e+00     0.000000   \n",
       "75%    777086.750000    95.000000    95.000000  0.000000e+00     0.000000   \n",
       "max    963939.000000   101.000000   101.000000  1.500000e-05     0.001111   \n",
       "\n",
       "            100028       100034       100041       100060        100061  \\\n",
       "count  9610.000000  9610.000000  9610.000000  9610.000000  9.610000e+03   \n",
       "mean      0.000038     0.000011     0.000128     0.000003  1.974741e-07   \n",
       "std       0.000530     0.000354     0.001304     0.000066  9.868021e-06   \n",
       "min       0.000000     0.000000     0.000000     0.000000  0.000000e+00   \n",
       "25%       0.000000     0.000000     0.000000     0.000000  0.000000e+00   \n",
       "50%       0.000000     0.000000     0.000000     0.000000  0.000000e+00   \n",
       "75%       0.000000     0.000000     0.000000     0.000000  0.000000e+00   \n",
       "max       0.042857     0.030000     0.047059     0.002857  6.250000e-04   \n",
       "\n",
       "           ...            964392        972612       978488       982437  \\\n",
       "count      ...       9610.000000  9.610000e+03  9610.000000  9610.000000   \n",
       "mean       ...          0.000001  6.771072e-15     0.000008     0.007639   \n",
       "std        ...          0.000098  6.630585e-13     0.000272     0.058937   \n",
       "min        ...          0.000000  0.000000e+00     0.000000     0.000000   \n",
       "25%        ...          0.000000  0.000000e+00     0.000000     0.000000   \n",
       "50%        ...          0.000000  0.000000e+00     0.000000     0.000000   \n",
       "75%        ...          0.000000  0.000000e+00     0.000000     0.000000   \n",
       "max        ...          0.007273  6.500000e-11     0.015000     0.729500   \n",
       "\n",
       "             982440       983685       983686       996041       998063  \\\n",
       "count  9.610000e+03  9610.000000  9610.000000  9610.000000  9610.000000   \n",
       "mean   1.309067e-07     0.000020     0.000004     0.000008     0.000001   \n",
       "std    8.014352e-06     0.000921     0.000091     0.000765     0.000082   \n",
       "min    0.000000e+00     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    0.000000e+00     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    0.000000e+00     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    0.000000e+00     0.000000     0.000000     0.000000     0.000000   \n",
       "max    6.640130e-04     0.088571     0.005000     0.075000     0.007002   \n",
       "\n",
       "             998168  \n",
       "count  9.610000e+03  \n",
       "mean   1.040583e-07  \n",
       "std    1.020090e-05  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    1.000000e-03  \n",
       "\n",
       "[8 rows x 1817 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "# get the indices of the array where it is not zero\n",
    "dst.iloc[0].nonzero()\n",
    "ds =  dst.iloc[0]\n",
    "print(len(ds.iloc[ds.nonzero()]))\n",
    "ds.iloc[ds.nonzero()]\n",
    "\n",
    "# I will need this for the embedding - but this means I will not be able to use batch - 128; \n",
    "# I will have to process every input individually\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Network  <a id=\"model\"></a> \n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------------------------\n",
    "def get_nns(): return str(ninp)+'*'+str(h[0])+'*'+str(h[1])+'*'+str(nout)\n",
    "def get_hpar(): return \"lr_%.0E_NN%s\" % (lr, get_nns())\n",
    "\n",
    "def logr(datep = '' , time='', it=1000, nn='', typ='TR', DS='', AC=0, num=0, AC3=0, AC10=0, desc='', startTime='', batch_size=128):\n",
    "    if desc == '': print(\"Log not recorded\"); return \n",
    "    LOG = \"../../_zfp/LOGT2.txt\"\n",
    "    f= open(LOG ,\"a+\") #w,a,\n",
    "    if datep != '':   dats = datep\n",
    "    else:             dats = datetime.now().strftime('%d.%m.%Y') \n",
    "    if time != '':    times = time\n",
    "    else:             times = datetime.now().strftime('%H:%M:%S') \n",
    "\n",
    "    line =  datetime.now().strftime('%d.%m.%Y') + '\\t' + times \n",
    "    line = line + '\\t' + str(it) + '\\t'+  get_nns() +  '\\t' + str(lr)\n",
    "    line = line + '\\t' + typ \n",
    "    line = line + '\\t' + str(DS) + '\\t' + str(AC) + '\\t' + str(num) + '\\t' + str(AC3) + '\\t' +  str(AC10) + '\\t' + desc \n",
    "    line = line + '\\t' + str(batch_size) + '\\t' +  startTime + '\\n' #new\n",
    "\n",
    "    f.write(line);  f.close()\n",
    "    print(\"___Log recorded\")    \n",
    "def restore_model(sess):   \n",
    "    saver= tf.train.Saver() \n",
    "    print(\"Model restored from file: %s\" % model_path)\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "# print(get_hpar())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [0, 0, 1, 0]\n",
      "1     [0, 0, 1, 0]\n",
      "2     [0, 0, 1, 0]\n",
      "3     [0, 0, 1, 0]\n",
      "4     [0, 0, 1, 0]\n",
      "5     [0, 0, 1, 0]\n",
      "6     [0, 0, 0, 1]\n",
      "7     [0, 0, 1, 0]\n",
      "8     [0, 0, 1, 0]\n",
      "9     [0, 0, 1, 0]\n",
      "10    [0, 0, 1, 0]\n",
      "Name: FP_P, dtype: object\n",
      "1814*100*40*4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs     = 10\n",
    "disp       = 5\n",
    "batch_s    = 64\n",
    "\n",
    "lr         = 0.01\n",
    "h          = [100 , 40]\n",
    "# h          = [40 , 10]\n",
    "\n",
    "ninp  = len(dst.columns) - 3 \n",
    "\n",
    "if   dType == 'C4':  nout = 4;   \n",
    "elif dType == 'C1': nout = 102;\n",
    "    \n",
    "#def convert_2List(dst): return {'label' : dst[\"label\"].as_matrix().tolist(), 'data' : dst[\"data\"].as_matrix().tolist()}\n",
    "# dst.insert(2, 'FP_P', dst['FP'].map(lambda x: cc( x )))  \n",
    "dst['FP_P'] = dst['FP'].map(lambda x: cc( x ))\n",
    "\n",
    "print(dst.loc[:10,'FP_P'])\n",
    "print( get_nns() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def build_network2(is_train=False):     # Simple NN - with batch normalization (high level)\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    \n",
    "    # h0 = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    h0 = tf.layers.dense( x, h[0], use_bias=False, activation=None )\n",
    "    h0 = tf.layers.batch_normalization(h0, training=is_train)\n",
    "    h0 = tf.nn.relu(h0)\n",
    "    # h0 = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    h1 = tf.layers.dense( h0, h[1], use_bias=False, activation=None )\n",
    "    h1 = tf.layers.batch_normalization(h1, training=is_train)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    # h1 = tf.nn.dropout(h1, kp)\n",
    "    \n",
    "    out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "    #out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    #out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        # softmaxT = tf.nn.softmax(out)\n",
    "        softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "\n",
    "        prediction=tf.reduce_max(y,1)\n",
    "        correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    return out, accuracy, softmaxT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network built\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "prediction, accuracy, softmaxT  = build_network2()\n",
    "print(\"network built\")\n",
    "\n",
    "with tf.name_scope(\"xent\"): #loss!\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    tf.summary.scalar(\"xent\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"): #opt!\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "saver= tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def build_network3(is_train=False):     # RNN - embeddings\n",
    "    global ninp, nout\n",
    "    kp = 0.5; \n",
    "    \n",
    "    # I cannot use embeddings because they only allow int32 and int64\n",
    "    # but my data is in percentage - decimals ... - experiment \n",
    "    # embedding = tf.Variable(tf.random_uniform((ninp, h[0]), -1, 1))\n",
    "    # h0 = tf.nn.embedding_lookup(embedding, x)\n",
    "    # h0 = tf.gather(embedding, x)\n",
    "\n",
    "    #only solution: \n",
    "    # - Train: \n",
    "    #index = dst[i].nonzero()\n",
    "    #for j in index:\n",
    "    #    wtemp.append(w0[j]) \n",
    "    #    xtmp.append(dst[i].iloc[j])\n",
    "    #wtemp.dot(xtmp)  \n",
    "    #run optimize feed_dict h0: h0, y: y ... \n",
    "    \n",
    "    # h0 = tf.layers.dense( x, h[0], activation=tf.nn.relu,  name )\n",
    "    # h0 = tf.layers.dense( x, h[0], use_bias=False, activation=None )\n",
    "    # h0 = tf.layers.batch_normalization(h0, training=is_train)\n",
    "    # h0 = tf.nn.relu(h0)\n",
    "    # h0 = tf.nn.dropout(h0, kp)\n",
    "    \n",
    "    h1 = tf.layers.dense( h0, h[1], use_bias=False, activation=None )\n",
    "    h1 = tf.layers.batch_normalization(h1, training=is_train)\n",
    "    h1 = tf.nn.relu(h1)\n",
    "    # h1 = tf.nn.dropout(h1, kp)\n",
    "    \n",
    "    out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "    out = tf.layers.batch_normalization(out, training=is_train)\n",
    "    out = tf.nn.relu(out)\n",
    "    # out = tf.nn.dropout(h0, kp)\n",
    " \n",
    "    # softmaxT = tf.nn.softmax(out)\n",
    "    softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "            \n",
    "    prediction=tf.reduce_max(y,1)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    return out, accuracy, softmaxT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def generator(z, output_dim, reuse=False, alpha=0.2, training=True, size_mult=128):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        out = tf.layers.dense( h1, nout, use_bias=False, activation=None )\n",
    "        out = tf.layers.batch_normalization(out, training=is_train)\n",
    "        out = tf.nn.relu(out)\n",
    "        # out = tf.nn.dropout(out, kp)\n",
    "        return out   \n",
    "    \n",
    "extra_class = 0        \n",
    "def discriminator(x, reuse=False, alpha=0.2, drop_rate=0., num_classes=10, size_mult=64):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(x, h[0], use_bias=False, activation=None )\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        #x1 = tf.nn.dropout(x1, kp)\n",
    "        x2 = tf.layers.dense( x1, h[1], use_bias=False, activation=None )\n",
    "        x2 = tf.layers.batch_normalization(, training=is_train)\n",
    "        h1 = tf.nn.relu(x2)\n",
    "        # h1 = tf.nn.dropout(x2, kp)\n",
    "        out = tf.layers.dense( h1, nout+extra_class, use_bias=False, activation=None )\n",
    "#         out = tf.layers.batch_normalization(out, training=is_train)\n",
    "#         out = tf.nn.relu(out)\n",
    "        # out = tf.nn.dropout(out, kp)\n",
    "\n",
    "        if extra_class:\n",
    "            real_class_logits, fake_class_logits = tf.split(class_logits, [num_classes, 1], 1)\n",
    "            assert fake_class_logits.get_shape()[1] == 1, fake_class_logits.get_shape()\n",
    "            fake_class_logits = tf.squeeze(fake_class_logits)\n",
    "        else:\n",
    "            real_class_logits = class_logits\n",
    "            fake_class_logits = 0.\n",
    "            \n",
    "            \n",
    "        return out, class_logits, gan_logits, features\n",
    "        \n",
    "def model_loss(input_real, input_z, output_dim, y, num_classes, label_mask, alpha=0.2, drop_rate=0.):\n",
    "\n",
    "    return d_loss, g_loss, correct, masked_correct, g_model\n",
    "\n",
    "def model_opt(d_loss, g_loss, learning_rate, beta1):\n",
    "\n",
    "\n",
    "def build_network4(is_train=False):     # GAN\n",
    "    global ninp, nout\n",
    "    \n",
    "    \n",
    "    gen = tf.nn.dropout(h0, kp)\n",
    " \n",
    "    # softmaxT = tf.nn.softmax(out)\n",
    "    softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "            \n",
    "    prediction=tf.reduce_max(y,1)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    \n",
    "    \n",
    "        # softmaxT = tf.nn.softmax(out)\n",
    "    softmaxT = tf.nn.top_k(tf.nn.softmax(out), 4)\n",
    "\n",
    "    prediction=tf.reduce_max(y,1)\n",
    "    correct_prediction = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    \n",
    "    return out, accuracy, softmaxT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network built\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"x\")\n",
    "z = tf.placeholder(tf.float32,   shape=[None, ninp], name=\"z\")\n",
    "y = tf.placeholder(tf.int16,     shape=[None, nout], name=\"y\")\n",
    "lm= tf.placeholder(tf.int32, (None), name='label_mask')\n",
    "\n",
    "prediction, accuracy, softmaxT  = build_network2()\n",
    "print(\"GAN built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network1 - TES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "def train(it = 100, disp=50, batch_size = 128):    \n",
    "    print(\"____TRAINING...\") #dst.loc[spn:,'FP_P'] dst.iloc[spn:, 3:]  \n",
    "    display_step =  disp \n",
    "\n",
    "    dataTest = {'label' : [] , 'data' :  [] };\n",
    "    #dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    \n",
    "    #dataT['data'].append(dataTest['data']) ;     md.dataT['label'].append(dataTest['label']) \n",
    "    print(\"data read - lenTrain={}-{} \" .format(len(dataTest[\"data\"]), len(dataTest[\"label\"]) ))\n",
    "\n",
    "    total_batch  = int(len(dst.loc[spn:]) / batch_size)\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # restore_model(sess)  #Run if I want to retrain an existing model\n",
    "        writer = tf.summary.FileWriter(MODEL_DIR+\"tboard/\", sess.graph )\n",
    "        \n",
    "        start = time.time()\n",
    "        for i in range(it):            \n",
    "            for ii, (xtb,ytb) in enumerate(get_batches(batch_size) ):\n",
    "                # xtb, ytb = dc.next_batch(batch_size, dataT['data'], dataT['label'])\n",
    "                sess.run(optimizer, feed_dict={x: xtb, y: ytb})\n",
    "                if ii % display_step ==0: #record_step == 0:\n",
    "                    [train_accuracy] = sess.run([accuracy], feed_dict={x: xtb, y: ytb }) \n",
    "                    #s = sess.run(summ, feed_dict={x: xtb, y: ytb })\n",
    "                    #[train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: xtb, y: ytb }) \n",
    "                    #writer.add_summary(s, i)\n",
    "                    \n",
    "                    elapsed_time = float(time.time() - start)\n",
    "                    reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "                    rp_s = str(reviews_per_second)[0:5]\n",
    "                    tr_ac = str(train_accuracy)[:5]  \n",
    "                    print('Epoch: {} batch: {} / {} - %Speed(it/disp_step): {} - tr_ac {}' .format(i, ii, total_batch, rp_s, tr_ac ))\n",
    "                    \n",
    "            #sess.run(optimizer, feed_dict={x: dataTest['data'], y: dataTest['label']})\n",
    "            #[train_accuracy] = sess.run([accuracy], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "            #print(\"ColC-{}\".format(train_accuracy))\n",
    "            \n",
    "            ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5]            \n",
    "            print(\"E Ac:\", ev_ac)\n",
    "        \n",
    "        # tr_ac = str(sess.run(accuracy, feed_dict={x: md.dataT['data'], y: md.dataT['label']}))[:5] \n",
    "        print(\"T Ac:\", tr_ac)\n",
    "        \n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    logr( it=it, typ='TR', DS=DESC, AC=tr_ac,num=len(dst)-spn, AC3=0, AC10=0, desc=des(), startTime=startTime, batch_size=batch_size )\n",
    "    logr( it=it, typ='EV', DS=DESC, AC=ev_ac,num=spn , AC3=0, AC10=0, desc=des() )\n",
    "#---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(dst.iloc[:spn-1,2:3]))\n",
    "# test = dst.loc[:2, 'FP_P']\n",
    "# print(type(test.tolist()))\n",
    "# test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate( ): \n",
    "    print(\"_____EVALUATION...\")\n",
    "    startTime = datetime.now().strftime('%H:%M:%S')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        tr_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[spn:, 3:],  y: dst.loc[spn:,'FP_P'].as_matrix().tolist()    }) )[:5]  \n",
    "        ev_ac = str(sess.run( accuracy, feed_dict={ x: dst.iloc[:spn, 3:],  y: dst.loc[:spn-1,'FP_P'].as_matrix().tolist()  }))[:5] \n",
    "        print(\"Training   Accuracy:\", tr_ac )\n",
    "        print(\"Evaluation Accuracy:\", ev_ac )\n",
    "        predv, softv = sess.run([prediction, softmaxT], feed_dict={x: dst.iloc[:spn, 3:]  }) # , y: md.dataE['label'] \n",
    "        # maxa = sess.run([prediction], feed_dict={y: predv })\n",
    "    print(\"Preview the first predictions:\")\n",
    "    for i in range(20):\n",
    "        print(\"RealVal: {}  - PP value: {}\".format( dc( dst.loc[:spn-1,'FP_P'][i])   , \n",
    "                                                    dc( predv.tolist()[i], np.max(predv[i]))  ))\n",
    "    gt3, gtM = check_perf_CN(softv, dst.loc[:spn-1,'FP_P'], False)\n",
    "    logr(  it=0, typ='EV', AC=ev_ac,DS=DESC, num=spn, AC3=gt3, AC10=gtM, desc=des(), startTime=startTime, batch_size=batch_s )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tests(url_test = 'url', p_col=False):  \n",
    "    print(\"_____TESTS...\")    \n",
    "    global DESC\n",
    "    # Load test data \n",
    "    dataTest = {'label' : [] , 'data' :  [] }; pred_val = []\n",
    "    if p_col: dataTest['data'], dataTest['label']  = feed_data(\"\", p_abs=False , d_st=True, p_col=True)   \n",
    "    else: \n",
    "        if url_test != 'url':  \n",
    "            json_data = url_test + \"data_json6.txt\"\n",
    "            tmpLab = pd.read_csv(url_test + \"datal6.csv\", sep=',', usecols=[0,1])    \n",
    "            tmpLab = tmpLab.loc[:,'fp']\n",
    "            abstcc = False\n",
    "        else: \n",
    "            json_str, tmpLab = get_data_test(\"FRALL\")\n",
    "            json_data = json.loads(json_str)\n",
    "            abstcc = True\n",
    "            DESC =  'matnrList...'\n",
    "        \n",
    "        dataTest['data']  = feed_data(json_data, p_abs=abstcc , d_st=True)\n",
    "        \n",
    "        dataTest['label'] = []\n",
    "        [dataTest['label'].append( cc(x) ) for x in tmpLab ]\n",
    "    # Predict data \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_model(sess)\n",
    "        # predv = sess.run( prediction, feed_dict={x: dataTest['data']}) \n",
    "        ts_acn = '0'\n",
    "        ts_acn, predv, sf = sess.run( [accuracy, prediction, softmaxT], feed_dict={x: dataTest['data'], y: dataTest['label']}) \n",
    "        ts_ac = str(ts_acn) \n",
    "        print(\"test ac = {}\".format(ts_ac))\n",
    "    # print(dataTest['label']);     print(sf)\n",
    "    range_ts = len(predv) if len(predv)<20 else 20\n",
    "    for i in range( range_ts ):\n",
    "        # print(\"RealVal: {}  - PP value: {}\".format( dc( dataTest['label'][i]), dc( predv.tolist()[i], np.max(predv[i]))  ))  \n",
    "        print(\"{} RealVal: {} - {} - PP: {} PR: {}\".format( i, dc( dataTest['label'][i]), sf[1][i][0],  sf[1][i], sf[0][i]   ))\n",
    "\n",
    "    # return\n",
    "    gt3, gtM = check_perf_CN(sf, dataTest[\"label\"], False)\n",
    "    logr( it=0, typ='TS', DS=DESC, AC=ts_acn ,num=len(dataTest[\"label\"]),  AC3=gt3, AC10=gtM, desc=des(), batch_size=batch_s )  \n",
    "\n",
    "    outfile = '../../_zfp/data/export2' \n",
    "    np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "    np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXECUTIONS <a id=\"exec\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i = 18\n",
    "# print(\"  PP: {} PR: {} \". format(   sf[1][i], sf[0][i]    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____TRAINING...\n",
      "data read - lenTrain=0-0 \n",
      "4608\n",
      "Epoch: 0 batch: 0 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.687\n",
      "Epoch: 0 batch: 5 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.656\n",
      "Epoch: 0 batch: 10 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.609\n",
      "Epoch: 0 batch: 15 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.625\n",
      "Epoch: 0 batch: 20 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.734\n",
      "Epoch: 0 batch: 25 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.625\n",
      "Epoch: 0 batch: 30 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.656\n",
      "Epoch: 0 batch: 35 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.718\n",
      "Epoch: 0 batch: 40 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.671\n",
      "Epoch: 0 batch: 45 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.781\n",
      "Epoch: 0 batch: 50 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.718\n",
      "Epoch: 0 batch: 55 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.812\n",
      "Epoch: 0 batch: 60 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.671\n",
      "Epoch: 0 batch: 65 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.781\n",
      "Epoch: 0 batch: 70 / 72 - %Speed(it/disp_step): 0.0 - tr_ac 0.796\n",
      "E Ac: 0.743\n",
      "4608\n",
      "Epoch: 1 batch: 0 / 72 - %Speed(it/disp_step): 0.773 - tr_ac 0.734\n",
      "Epoch: 1 batch: 5 / 72 - %Speed(it/disp_step): 0.734 - tr_ac 0.781\n",
      "Epoch: 1 batch: 10 / 72 - %Speed(it/disp_step): 0.700 - tr_ac 0.671\n",
      "Epoch: 1 batch: 15 / 72 - %Speed(it/disp_step): 0.668 - tr_ac 0.812\n",
      "Epoch: 1 batch: 20 / 72 - %Speed(it/disp_step): 0.640 - tr_ac 0.781\n",
      "Epoch: 1 batch: 25 / 72 - %Speed(it/disp_step): 0.614 - tr_ac 0.796\n",
      "Epoch: 1 batch: 30 / 72 - %Speed(it/disp_step): 0.590 - tr_ac 0.75\n",
      "Epoch: 1 batch: 35 / 72 - %Speed(it/disp_step): 0.567 - tr_ac 0.843\n",
      "Epoch: 1 batch: 40 / 72 - %Speed(it/disp_step): 0.547 - tr_ac 0.765\n",
      "Epoch: 1 batch: 45 / 72 - %Speed(it/disp_step): 0.527 - tr_ac 0.843\n",
      "Epoch: 1 batch: 50 / 72 - %Speed(it/disp_step): 0.510 - tr_ac 0.765\n",
      "Epoch: 1 batch: 55 / 72 - %Speed(it/disp_step): 0.492 - tr_ac 0.812\n",
      "Epoch: 1 batch: 60 / 72 - %Speed(it/disp_step): 0.477 - tr_ac 0.718\n",
      "Epoch: 1 batch: 65 / 72 - %Speed(it/disp_step): 0.462 - tr_ac 0.765\n",
      "Epoch: 1 batch: 70 / 72 - %Speed(it/disp_step): 0.448 - tr_ac 0.812\n",
      "E Ac: 0.804\n",
      "4608\n",
      "Epoch: 2 batch: 0 / 72 - %Speed(it/disp_step): 0.814 - tr_ac 0.812\n",
      "Epoch: 2 batch: 5 / 72 - %Speed(it/disp_step): 0.792 - tr_ac 0.734\n",
      "Epoch: 2 batch: 10 / 72 - %Speed(it/disp_step): 0.772 - tr_ac 0.781\n",
      "Epoch: 2 batch: 15 / 72 - %Speed(it/disp_step): 0.752 - tr_ac 0.843\n",
      "Epoch: 2 batch: 20 / 72 - %Speed(it/disp_step): 0.733 - tr_ac 0.875\n",
      "Epoch: 2 batch: 25 / 72 - %Speed(it/disp_step): 0.715 - tr_ac 0.890\n",
      "Epoch: 2 batch: 30 / 72 - %Speed(it/disp_step): 0.699 - tr_ac 0.812\n",
      "Epoch: 2 batch: 35 / 72 - %Speed(it/disp_step): 0.682 - tr_ac 0.906\n",
      "Epoch: 2 batch: 40 / 72 - %Speed(it/disp_step): 0.666 - tr_ac 0.828\n",
      "Epoch: 2 batch: 45 / 72 - %Speed(it/disp_step): 0.652 - tr_ac 0.921\n",
      "Epoch: 2 batch: 50 / 72 - %Speed(it/disp_step): 0.637 - tr_ac 0.812\n",
      "Epoch: 2 batch: 55 / 72 - %Speed(it/disp_step): 0.624 - tr_ac 0.890\n",
      "Epoch: 2 batch: 60 / 72 - %Speed(it/disp_step): 0.611 - tr_ac 0.812\n",
      "Epoch: 2 batch: 65 / 72 - %Speed(it/disp_step): 0.599 - tr_ac 0.859\n",
      "Epoch: 2 batch: 70 / 72 - %Speed(it/disp_step): 0.587 - tr_ac 0.859\n",
      "E Ac: 0.829\n",
      "4608\n",
      "Epoch: 3 batch: 0 / 72 - %Speed(it/disp_step): 0.820 - tr_ac 0.812\n",
      "Epoch: 3 batch: 5 / 72 - %Speed(it/disp_step): 0.805 - tr_ac 0.765\n",
      "Epoch: 3 batch: 10 / 72 - %Speed(it/disp_step): 0.791 - tr_ac 0.859\n",
      "Epoch: 3 batch: 15 / 72 - %Speed(it/disp_step): 0.774 - tr_ac 0.828\n",
      "Epoch: 3 batch: 20 / 72 - %Speed(it/disp_step): 0.752 - tr_ac 0.859\n",
      "Epoch: 3 batch: 25 / 72 - %Speed(it/disp_step): 0.735 - tr_ac 0.890\n",
      "Epoch: 3 batch: 30 / 72 - %Speed(it/disp_step): 0.718 - tr_ac 0.859\n",
      "Epoch: 3 batch: 35 / 72 - %Speed(it/disp_step): 0.702 - tr_ac 0.906\n",
      "Epoch: 3 batch: 40 / 72 - %Speed(it/disp_step): 0.689 - tr_ac 0.828\n",
      "Epoch: 3 batch: 45 / 72 - %Speed(it/disp_step): 0.677 - tr_ac 0.921\n",
      "Epoch: 3 batch: 50 / 72 - %Speed(it/disp_step): 0.663 - tr_ac 0.890\n",
      "Epoch: 3 batch: 55 / 72 - %Speed(it/disp_step): 0.652 - tr_ac 0.937\n",
      "Epoch: 3 batch: 60 / 72 - %Speed(it/disp_step): 0.640 - tr_ac 0.859\n",
      "Epoch: 3 batch: 65 / 72 - %Speed(it/disp_step): 0.629 - tr_ac 0.796\n",
      "Epoch: 3 batch: 70 / 72 - %Speed(it/disp_step): 0.618 - tr_ac 0.937\n",
      "E Ac: 0.790\n",
      "4608\n",
      "Epoch: 4 batch: 0 / 72 - %Speed(it/disp_step): 0.776 - tr_ac 0.812\n",
      "Epoch: 4 batch: 5 / 72 - %Speed(it/disp_step): 0.764 - tr_ac 0.812\n",
      "Epoch: 4 batch: 10 / 72 - %Speed(it/disp_step): 0.751 - tr_ac 0.875\n",
      "Epoch: 4 batch: 15 / 72 - %Speed(it/disp_step): 0.740 - tr_ac 0.843\n",
      "Epoch: 4 batch: 20 / 72 - %Speed(it/disp_step): 0.729 - tr_ac 0.890\n",
      "Epoch: 4 batch: 25 / 72 - %Speed(it/disp_step): 0.718 - tr_ac 0.890\n",
      "Epoch: 4 batch: 30 / 72 - %Speed(it/disp_step): 0.707 - tr_ac 0.875\n",
      "Epoch: 4 batch: 35 / 72 - %Speed(it/disp_step): 0.697 - tr_ac 0.906\n",
      "Epoch: 4 batch: 40 / 72 - %Speed(it/disp_step): 0.687 - tr_ac 0.859\n",
      "Epoch: 4 batch: 45 / 72 - %Speed(it/disp_step): 0.677 - tr_ac 0.968\n",
      "Epoch: 4 batch: 50 / 72 - %Speed(it/disp_step): 0.667 - tr_ac 0.921\n",
      "Epoch: 4 batch: 55 / 72 - %Speed(it/disp_step): 0.657 - tr_ac 0.968\n",
      "Epoch: 4 batch: 60 / 72 - %Speed(it/disp_step): 0.644 - tr_ac 0.921\n",
      "Epoch: 4 batch: 65 / 72 - %Speed(it/disp_step): 0.634 - tr_ac 0.906\n",
      "Epoch: 4 batch: 70 / 72 - %Speed(it/disp_step): 0.624 - tr_ac 0.968\n",
      "E Ac: 0.835\n",
      "4608\n",
      "Epoch: 5 batch: 0 / 72 - %Speed(it/disp_step): 0.741 - tr_ac 0.828\n",
      "Epoch: 5 batch: 5 / 72 - %Speed(it/disp_step): 0.731 - tr_ac 0.843\n",
      "Epoch: 5 batch: 10 / 72 - %Speed(it/disp_step): 0.722 - tr_ac 0.875\n",
      "Epoch: 5 batch: 15 / 72 - %Speed(it/disp_step): 0.712 - tr_ac 0.859\n",
      "Epoch: 5 batch: 20 / 72 - %Speed(it/disp_step): 0.704 - tr_ac 0.906\n",
      "Epoch: 5 batch: 25 / 72 - %Speed(it/disp_step): 0.696 - tr_ac 0.906\n",
      "Epoch: 5 batch: 30 / 72 - %Speed(it/disp_step): 0.687 - tr_ac 0.890\n",
      "Epoch: 5 batch: 35 / 72 - %Speed(it/disp_step): 0.679 - tr_ac 0.937\n",
      "Epoch: 5 batch: 40 / 72 - %Speed(it/disp_step): 0.671 - tr_ac 0.890\n",
      "Epoch: 5 batch: 45 / 72 - %Speed(it/disp_step): 0.662 - tr_ac 0.968\n",
      "Epoch: 5 batch: 50 / 72 - %Speed(it/disp_step): 0.651 - tr_ac 0.906\n",
      "Epoch: 5 batch: 55 / 72 - %Speed(it/disp_step): 0.642 - tr_ac 0.968\n",
      "Epoch: 5 batch: 60 / 72 - %Speed(it/disp_step): 0.635 - tr_ac 0.921\n",
      "Epoch: 5 batch: 65 / 72 - %Speed(it/disp_step): 0.627 - tr_ac 0.953\n",
      "Epoch: 5 batch: 70 / 72 - %Speed(it/disp_step): 0.620 - tr_ac 0.968\n",
      "E Ac: 0.844\n",
      "4608\n",
      "Epoch: 6 batch: 0 / 72 - %Speed(it/disp_step): 0.717 - tr_ac 0.875\n",
      "Epoch: 6 batch: 5 / 72 - %Speed(it/disp_step): 0.710 - tr_ac 0.859\n",
      "Epoch: 6 batch: 10 / 72 - %Speed(it/disp_step): 0.704 - tr_ac 0.921\n",
      "Epoch: 6 batch: 15 / 72 - %Speed(it/disp_step): 0.697 - tr_ac 0.875\n",
      "Epoch: 6 batch: 20 / 72 - %Speed(it/disp_step): 0.691 - tr_ac 0.921\n",
      "Epoch: 6 batch: 25 / 72 - %Speed(it/disp_step): 0.684 - tr_ac 0.859\n",
      "Epoch: 6 batch: 30 / 72 - %Speed(it/disp_step): 0.676 - tr_ac 0.921\n",
      "Epoch: 6 batch: 35 / 72 - %Speed(it/disp_step): 0.670 - tr_ac 0.968\n",
      "Epoch: 6 batch: 40 / 72 - %Speed(it/disp_step): 0.664 - tr_ac 0.890\n",
      "Epoch: 6 batch: 45 / 72 - %Speed(it/disp_step): 0.657 - tr_ac 0.968\n",
      "Epoch: 6 batch: 50 / 72 - %Speed(it/disp_step): 0.650 - tr_ac 0.921\n",
      "Epoch: 6 batch: 55 / 72 - %Speed(it/disp_step): 0.644 - tr_ac 0.953\n",
      "Epoch: 6 batch: 60 / 72 - %Speed(it/disp_step): 0.639 - tr_ac 0.921\n",
      "Epoch: 6 batch: 65 / 72 - %Speed(it/disp_step): 0.633 - tr_ac 0.953\n",
      "Epoch: 6 batch: 70 / 72 - %Speed(it/disp_step): 0.628 - tr_ac 0.968\n",
      "E Ac: 0.844\n",
      "4608\n",
      "Epoch: 7 batch: 0 / 72 - %Speed(it/disp_step): 0.712 - tr_ac 0.875\n",
      "Epoch: 7 batch: 5 / 72 - %Speed(it/disp_step): 0.705 - tr_ac 0.859\n",
      "Epoch: 7 batch: 10 / 72 - %Speed(it/disp_step): 0.700 - tr_ac 0.937\n",
      "Epoch: 7 batch: 15 / 72 - %Speed(it/disp_step): 0.694 - tr_ac 0.875\n",
      "Epoch: 7 batch: 20 / 72 - %Speed(it/disp_step): 0.688 - tr_ac 0.921\n",
      "Epoch: 7 batch: 25 / 72 - %Speed(it/disp_step): 0.682 - tr_ac 0.906\n",
      "Epoch: 7 batch: 30 / 72 - %Speed(it/disp_step): 0.677 - tr_ac 0.921\n",
      "Epoch: 7 batch: 35 / 72 - %Speed(it/disp_step): 0.673 - tr_ac 0.968\n",
      "Epoch: 7 batch: 40 / 72 - %Speed(it/disp_step): 0.668 - tr_ac 0.906\n",
      "Epoch: 7 batch: 45 / 72 - %Speed(it/disp_step): 0.664 - tr_ac 0.984\n",
      "Epoch: 7 batch: 50 / 72 - %Speed(it/disp_step): 0.659 - tr_ac 0.921\n",
      "Epoch: 7 batch: 55 / 72 - %Speed(it/disp_step): 0.655 - tr_ac 0.968\n",
      "Epoch: 7 batch: 60 / 72 - %Speed(it/disp_step): 0.651 - tr_ac 0.937\n",
      "Epoch: 7 batch: 65 / 72 - %Speed(it/disp_step): 0.647 - tr_ac 0.937\n",
      "Epoch: 7 batch: 70 / 72 - %Speed(it/disp_step): 0.643 - tr_ac 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E Ac: 0.851\n",
      "4608\n",
      "Epoch: 8 batch: 0 / 72 - %Speed(it/disp_step): 0.717 - tr_ac 0.890\n",
      "Epoch: 8 batch: 5 / 72 - %Speed(it/disp_step): 0.712 - tr_ac 0.921\n",
      "Epoch: 8 batch: 10 / 72 - %Speed(it/disp_step): 0.706 - tr_ac 0.921\n",
      "Epoch: 8 batch: 15 / 72 - %Speed(it/disp_step): 0.700 - tr_ac 0.890\n",
      "Epoch: 8 batch: 20 / 72 - %Speed(it/disp_step): 0.694 - tr_ac 0.937\n",
      "Epoch: 8 batch: 25 / 72 - %Speed(it/disp_step): 0.689 - tr_ac 0.890\n",
      "Epoch: 8 batch: 30 / 72 - %Speed(it/disp_step): 0.683 - tr_ac 0.968\n",
      "Epoch: 8 batch: 35 / 72 - %Speed(it/disp_step): 0.678 - tr_ac 0.953\n",
      "Epoch: 8 batch: 40 / 72 - %Speed(it/disp_step): 0.673 - tr_ac 0.906\n",
      "Epoch: 8 batch: 45 / 72 - %Speed(it/disp_step): 0.668 - tr_ac 1.0\n",
      "Epoch: 8 batch: 50 / 72 - %Speed(it/disp_step): 0.662 - tr_ac 0.937\n",
      "Epoch: 8 batch: 55 / 72 - %Speed(it/disp_step): 0.658 - tr_ac 0.984\n",
      "Epoch: 8 batch: 60 / 72 - %Speed(it/disp_step): 0.653 - tr_ac 0.953\n",
      "Epoch: 8 batch: 65 / 72 - %Speed(it/disp_step): 0.648 - tr_ac 0.953\n",
      "Epoch: 8 batch: 70 / 72 - %Speed(it/disp_step): 0.643 - tr_ac 0.984\n",
      "E Ac: 0.857\n",
      "4608\n",
      "Epoch: 9 batch: 0 / 72 - %Speed(it/disp_step): 0.706 - tr_ac 0.906\n",
      "Epoch: 9 batch: 5 / 72 - %Speed(it/disp_step): 0.701 - tr_ac 0.968\n",
      "Epoch: 9 batch: 10 / 72 - %Speed(it/disp_step): 0.696 - tr_ac 0.953\n",
      "Epoch: 9 batch: 15 / 72 - %Speed(it/disp_step): 0.691 - tr_ac 0.890\n",
      "Epoch: 9 batch: 20 / 72 - %Speed(it/disp_step): 0.686 - tr_ac 0.906\n",
      "Epoch: 9 batch: 25 / 72 - %Speed(it/disp_step): 0.681 - tr_ac 0.875\n",
      "Epoch: 9 batch: 30 / 72 - %Speed(it/disp_step): 0.676 - tr_ac 0.984\n",
      "Epoch: 9 batch: 35 / 72 - %Speed(it/disp_step): 0.671 - tr_ac 0.937\n",
      "Epoch: 9 batch: 40 / 72 - %Speed(it/disp_step): 0.667 - tr_ac 0.921\n",
      "Epoch: 9 batch: 45 / 72 - %Speed(it/disp_step): 0.663 - tr_ac 0.984\n",
      "Epoch: 9 batch: 50 / 72 - %Speed(it/disp_step): 0.658 - tr_ac 0.937\n",
      "Epoch: 9 batch: 55 / 72 - %Speed(it/disp_step): 0.654 - tr_ac 0.968\n",
      "Epoch: 9 batch: 60 / 72 - %Speed(it/disp_step): 0.650 - tr_ac 0.953\n",
      "Epoch: 9 batch: 65 / 72 - %Speed(it/disp_step): 0.645 - tr_ac 0.953\n",
      "Epoch: 9 batch: 70 / 72 - %Speed(it/disp_step): 0.640 - tr_ac 1.0\n",
      "E Ac: 0.854\n",
      "T Ac: 1.0\n",
      "Model saved in file: ../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/model.ckpt\n",
      "Optimization Finished!\n",
      "___Log recorded\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "train(epochs, disp, batch_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____EVALUATION...\n",
      "Model restored from file: ../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/model.ckpt\n",
      "Training   Accuracy: 0.954\n",
      "Evaluation Accuracy: 0.854\n",
      "Preview the first predictions:\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 2\n",
      "RealVal: 2  - PP value: 2\n",
      "RealVal: 3  - PP value: 3\n",
      "RealVal: 2  - PP value: 2\n",
      "denormalization all Evaluation : 5000 = 5000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "Total: 5000 GT3: 729  GTM: 729\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "DESC       = \"FRFLO\"\n",
    "evaluate( )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____TESTS...\n",
      "input-no=1814\n",
      "cycle: 0\n",
      "m:308210-c:657716 not included\n",
      "m:607654-c:659609 not included\n",
      "m:632416-c:100182 not included\n",
      "m:632416-c:131026 not included\n",
      "m:632416-c:600247 not included\n",
      "m:632416-c:107714 not included\n",
      "m:632416-c:104774 not included\n",
      "m:632416-c:614552 not included\n",
      "m:632416-c:600236 not included\n",
      "m:632416-c:105671 not included\n",
      "m:632416-c:131306 not included\n",
      "m:632416-c:107353 not included\n",
      "m:632416-c:600180 not included\n",
      "m:632416-c:131305 not included\n",
      "m:632416-c:600224 not included\n",
      "m:632416-c:192114 not included\n",
      "m:632416-c:600338 not included\n",
      "m:632416-c:106148 not included\n",
      "m:632416-c:600227 not included\n",
      "m:632416-c:614235 not included\n",
      "m:632416-c:131303 not included\n",
      "m:632416-c:600256 not included\n",
      "m:632416-c:131357 not included\n",
      "m:632416-c:181023 not included\n",
      "m:632416-c:131341 not included\n",
      "m:632416-c:600252 not included\n",
      "m:632416-c:600229 not included\n",
      "m:632416-c:107159 not included\n",
      "m:632416-c:192002 not included\n",
      "m:632416-c:600237 not included\n",
      "m:632416-c:104814 not included\n",
      "m:632416-c:104557 not included\n",
      "m:632632-c:906246 not included\n",
      "m:632632-c:906228 not included\n",
      "m:632632-c:906195 not included\n",
      "m:632632-c:900081 not included\n",
      "m:632632-c:643368 not included\n",
      "m:632632-c:906234 not included\n",
      "m:632632-c:905210 not included\n",
      "m:632632-c:178713 not included\n",
      "m:632632-c:104241 not included\n",
      "m:632632-c:904987 not included\n",
      "m:633650-c:178429 not included\n",
      "m:633652-c:178429 not included\n",
      "m:634190-c:160065 not included\n",
      "m:634190-c:657531 not included\n",
      "m:634190-c:172585 not included\n",
      "m:634190-c:656991 not included\n",
      "m:634190-c:116216 not included\n",
      "m:634190-c:613113 not included\n",
      "m:634190-c:164136 not included\n",
      "m:634330-c:600283 not included\n",
      "m:634330-c:903936 not included\n",
      "m:634330-c:131168 not included\n",
      "m:634832-c:100954 not included\n",
      "m:634832-c:613373 not included\n",
      "m:634832-c:100985 not included\n",
      "m:635055-c:192517 not included\n",
      "m:635056-c:173437 not included\n",
      "m:635056-c:192517 not included\n",
      "m:635059-c:173437 not included\n",
      "m:635059-c:192161 not included\n",
      "m:635059-c:107854 not included\n",
      "m:635059-c:192517 not included\n",
      "m:635955-c:178429 not included\n",
      "m:637117-c:100013 not included\n",
      "m:640737-c:903656 not included\n",
      "m:640744-c:131460 not included\n",
      "m:640745-c:131460 not included\n",
      "m:641547-c:131357 not included\n",
      "m:641547-c:602537 not included\n",
      "m:641547-c:659973 not included\n",
      "m:641547-c:106929 not included\n",
      "m:641547-c:657707 not included\n",
      "m:641547-c:192002 not included\n",
      "m:641547-c:107353 not included\n",
      "m:641547-c:115614 not included\n",
      "m:641547-c:657856 not included\n",
      "m:641547-c:600324 not included\n",
      "m:641547-c:181204 not included\n",
      "m:641547-c:106148 not included\n",
      "m:641547-c:614235 not included\n",
      "m:641547-c:657858 not included\n",
      "m:642045-c:131460 not included\n",
      "m:642045-c:903656 not included\n",
      "m:642077-c:903656 not included\n",
      "m:642078-c:903656 not included\n",
      "m:642410-c:105370 not included\n",
      "m:642584-c:900175 not included\n",
      "m:642584-c:100103 not included\n",
      "m:642904-c:904694 not included\n",
      "m:648652-c:173462 not included\n",
      "m:648652-c:621180 not included\n",
      "m:648652-c:656153 not included\n",
      "m:648652-c:111545 not included\n",
      "m:648652-c:106234 not included\n",
      "m:648652-c:621270 not included\n",
      "m:648652-c:128713 not included\n",
      "m:648652-c:115121 not included\n",
      "m:648652-c:657014 not included\n",
      "m:648652-c:660450 not included\n",
      "m:648652-c:172904 not included\n",
      "m:648652-c:106233 not included\n",
      "m:648652-c:128714 not included\n",
      "m:648652-c:660472 not included\n",
      "m:648652-c:613621 not included\n",
      "m:649248-c:172381 not included\n",
      "m:649248-c:621329 not included\n",
      "m:654512-c:188069 not included\n",
      "m:654512-c:657280 not included\n",
      "m:654512-c:107544 not included\n",
      "m:654512-c:173483 not included\n",
      "m:657282-c:619724 not included\n",
      "m:657282-c:660551 not included\n",
      "m:668545-c:996058 not included\n",
      "m:668545-c:906371 not included\n",
      "m:668545-c:106229 not included\n",
      "m:668545-c:600324 not included\n",
      "m:668545-c:906339 not included\n",
      "m:668545-c:192002 not included\n",
      "m:668545-c:106228 not included\n",
      "m:668545-c:906342 not included\n",
      "m:669362-c:762238 not included\n",
      "m:671711-c:100984 not included\n",
      "m:671711-c:100954 not included\n",
      "m:672522-c:100509 not included\n",
      "m:728171-c:903016 not included\n",
      "m:942926-c:100264 not included\n",
      "m:942926-c:182161 not included\n",
      "m:942926-c:164401 not included\n",
      "m:942926-c:130180 not included\n",
      "m:942926-c:110098 not included\n",
      "m:942926-c:131137 not included\n",
      "m:942926-c:131320 not included\n",
      "m:942926-c:131186 not included\n",
      "m:942926-c:690957 not included\n",
      "m:942926-c:131359 not included\n",
      "m:942926-c:114089 not included\n",
      "m:942926-c:131217 not included\n",
      "Counter of comp. not included :\n",
      "Counter({903656: 4, 192002: 3, 192517: 3, 131460: 3, 178429: 3, 600324: 2, 131357: 2, 107353: 2, 100954: 2, 614235: 2, 173437: 2, 106148: 2, 903936: 1, 906246: 1, 100103: 1, 131341: 1, 600237: 1, 621329: 1, 600338: 1, 107544: 1, 656153: 1, 904987: 1, 181023: 1, 106929: 1, 643368: 1, 172585: 1, 657707: 1, 659973: 1, 104241: 1, 657716: 1, 160065: 1, 104774: 1, 660551: 1, 107854: 1, 900175: 1, 100182: 1, 172381: 1, 656991: 1, 131168: 1, 130180: 1, 906339: 1, 131186: 1, 906342: 1, 131217: 1, 172904: 1, 104557: 1, 104814: 1, 903016: 1, 192114: 1, 600180: 1, 657014: 1, 100984: 1, 100985: 1, 657531: 1, 621180: 1, 762238: 1, 657280: 1, 600256: 1, 906371: 1, 131137: 1, 107714: 1, 182161: 1, 110098: 1, 106228: 1, 173462: 1, 107159: 1, 614552: 1, 659609: 1, 105370: 1, 100509: 1, 115614: 1, 600224: 1, 192161: 1, 600227: 1, 600229: 1, 900081: 1, 100264: 1, 602537: 1, 173483: 1, 600236: 1, 100013: 1, 115121: 1, 660472: 1, 600247: 1, 111545: 1, 131359: 1, 600252: 1, 106229: 1, 657856: 1, 657858: 1, 178713: 1, 105671: 1, 128713: 1, 128714: 1, 619724: 1, 905210: 1, 131026: 1, 906195: 1, 181204: 1, 164401: 1, 621270: 1, 106233: 1, 996058: 1, 600283: 1, 131320: 1, 906234: 1, 188069: 1, 660450: 1, 690957: 1, 131303: 1, 131305: 1, 131306: 1, 164136: 1, 906228: 1, 613621: 1, 904694: 1, 114089: 1, 116216: 1, 613113: 1, 106234: 1, 613373: 1})\n",
      "Model restored from file: ../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../../_zfp/data/my_graph/FRFLO/FRFLOMODJJ1/model.ckpt\n",
      "test ac = 0.863821\n",
      "0 RealVal: 1 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   7.32787164e-09   2.78263008e-13   4.62253594e-14]\n",
      "1 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  8.54485571e-01   1.22337334e-01   2.31660847e-02   1.10127303e-05]\n",
      "2 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  9.99999762e-01   2.69267417e-07   4.75805839e-10   5.33658881e-12]\n",
      "3 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  9.70701158e-01   2.79200487e-02   1.36153935e-03   1.72610289e-05]\n",
      "4 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   3.94594331e-08   1.21685384e-10   3.38141320e-12]\n",
      "5 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.35286522e-01   6.45302907e-02   1.82593882e-04   6.03824219e-07]\n",
      "6 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  8.25562775e-01   1.73840895e-01   5.94793586e-04   1.45941806e-06]\n",
      "7 RealVal: 2 - 3 - PP: [3 2 1 0] PR: [  7.12804615e-01   2.87071764e-01   1.23126811e-04   5.61312277e-07]\n",
      "8 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.16708291e-01   8.28469396e-02   4.41988639e-04   2.76330229e-06]\n",
      "9 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   4.19246060e-09   8.20199880e-11   3.68572326e-14]\n",
      "10 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.78307843e-01   2.16747429e-02   1.74213928e-05   1.77058421e-08]\n",
      "11 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  7.39393413e-01   2.58444339e-01   2.16135150e-03   9.54968073e-07]\n",
      "12 RealVal: 2 - 2 - PP: [2 1 3 0] PR: [  9.99995589e-01   3.61604725e-06   8.00513703e-07   2.38946507e-09]\n",
      "13 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.44140911e-01   5.58332875e-02   2.57139800e-05   3.11414787e-08]\n",
      "14 RealVal: 2 - 2 - PP: [2 1 0 3] PR: [  9.97345150e-01   2.65484676e-03   4.80047460e-11   9.02620483e-28]\n",
      "15 RealVal: 3 - 2 - PP: [2 1 0 3] PR: [  9.99999762e-01   1.80776382e-07   1.44947476e-13   9.09504551e-21]\n",
      "16 RealVal: 3 - 2 - PP: [2 1 3 0] PR: [  1.00000000e+00   7.98824917e-09   1.60445511e-11   4.52384271e-14]\n",
      "17 RealVal: 2 - 2 - PP: [2 1 0 3] PR: [  1.00000000e+00   3.26021277e-09   6.34921667e-15   1.55375303e-16]\n",
      "18 RealVal: 2 - 2 - PP: [2 3 1 0] PR: [  9.99999881e-01   1.05568496e-07   5.11957552e-08   1.04028125e-12]\n",
      "19 RealVal: 3 - 3 - PP: [3 2 1 0] PR: [  9.75659907e-01   2.43396480e-02   4.01118143e-07   4.28370672e-11]\n",
      "denormalization all Evaluation : 984 = 984\n",
      "0\n",
      "Total: 984 GT3: 134  GTM: 134\n",
      "___Log recorded\n"
     ]
    }
   ],
   "source": [
    "url_test = \"../../_zfp/data/FREXP1/\" ; DESC     = \"FREXP1_6\"\n",
    "tests(url_test, p_col=False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRITE EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import xlsxwriter\n",
    "# outfile = '../../_zfp/data/export.xlsx' \n",
    "\n",
    "# workbook   = xlsxwriter.Workbook(outfile)\n",
    "# worksheet1 = workbook.add_worksheet()\n",
    "# worksheet1.write('A1', 'M')\n",
    "# worksheet1.write(0, 0, 'Hello')  \n",
    "# for i in range(len(sf[0])):\n",
    "#     worksheet1.write(0, i , sf[0][i])  \n",
    "#     worksheet1.write(1, i , sf[1][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import csv\n",
    "# outfile = '../../_zfp/data/export.csv' \n",
    "# f2= open(outfile,\"a+\")\n",
    "# output_writer = csv.writer(f2, delimiter=\"\\t\")\n",
    "# output_writer.writerows(sf)\n",
    "# f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# outfile = '../../_zfp/data/export2' \n",
    "# np.savetxt(outfile + '.csv', sf[1], delimiter=',')\n",
    "# np.savetxt(outfile + 'PRO.csv', sf[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display visualizations <a id=\"disp\"/>\n",
    "[go back](#index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = outfile = '../../_zfp/data/FRFLO/datasc.csv' \n",
    "dst  =  pd.read_csv( tf.gfile.Open(path), sep=None, skipinitialspace=True,  engine=\"python\")\n",
    "Y  = dst.loc[:,'FP'].as_matrix().tolist()\n",
    "X  = dst.loc[:, 'M'].as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2279db38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 2 - Create plot. \n",
    "a = 1\n",
    "if a == 0: \n",
    "    plt.hist(Y)\n",
    "else: \n",
    "    plt.xlabel('M')\n",
    "    plt.ylabel('FP')\n",
    "    plt.grid(True)\n",
    "    N = 2 #50\n",
    "    colors = np.random.rand(N)\n",
    "    area = 1 #np.pi * (15 * np.random.rand(N))**2  # 0 to 15 point radii\n",
    "\n",
    "    #plt.plot(X, Y, color='blue', marker='o', label='FP Comp')\n",
    "    #plt.plot(X, Y, 'bo', label='FP Comp')\n",
    "    plt.scatter(X,Y, s=6, c='b', marker='o', cmap=None, norm=None, vmin=60, vmax=101, alpha=None,  label='FP Comp')\n",
    "    # plt.plot(X, Y,  s=area, c=colors, alpha=0.5) #'bo', label='FP Comp',\n",
    "    plt.legend()\n",
    "\n",
    "# 3 - Display plot. \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
